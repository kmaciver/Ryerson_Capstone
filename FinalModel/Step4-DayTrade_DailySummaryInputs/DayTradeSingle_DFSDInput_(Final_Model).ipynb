{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "DayTradeSingle_DFSDInput (Final Model).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmaciver/Ryerson_Capstone/blob/master/FinalModel/Step4-DayTrade_DailySummaryInputs/DayTradeSingle_DFSDInput_(Final_Model).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9hHMfSFdQAT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "256cde20-fb4c-4b38-9f90-39741f3d3ee8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sFpaBQvcURQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, QuantileTransformer\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyHGVUHWcUSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Input, Dense, GRU, Embedding, LSTM, TimeDistributed, Lambda, Dropout\n",
        "from tensorflow.python.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras import losses\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import random as rand\n",
        "from random import randint\n",
        "from numpy.random import seed\n",
        "seed(10)\n",
        "from tensorflow.compat.v1 import set_random_seed\n",
        "set_random_seed(2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3LxzHxTcUSQ",
        "colab_type": "code",
        "outputId": "181fbc8c-9d05-479f-e731-a3df23d96dba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        }
      },
      "source": [
        "file_path = \"/content/drive/My Drive/Capstone/Data Exploration/Day_trade_data.csv\"\n",
        "DayTrade = pd.read_csv(file_path, index_col='Time')\n",
        "DayTrade = DayTrade.drop([DayTrade.columns[0]] ,  axis='columns')\n",
        "DayTrade.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume_.BTC.</th>\n",
              "      <th>Volume_.Currency.</th>\n",
              "      <th>Weighted_Price</th>\n",
              "      <th>date</th>\n",
              "      <th>Open_RoC</th>\n",
              "      <th>High_RoC</th>\n",
              "      <th>Low_RoC</th>\n",
              "      <th>Close_RoC</th>\n",
              "      <th>Weighted_Price_RoC</th>\n",
              "      <th>RSI</th>\n",
              "      <th>MACD_index</th>\n",
              "      <th>slow_stoch</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-04-03 00:00:00</th>\n",
              "      <td>116.00</td>\n",
              "      <td>116.00</td>\n",
              "      <td>116.00</td>\n",
              "      <td>116.00</td>\n",
              "      <td>31.713233</td>\n",
              "      <td>3678.735005</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>2013-04-03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>-0.36038</td>\n",
              "      <td>0.084906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 00:01:00</th>\n",
              "      <td>116.00</td>\n",
              "      <td>116.00</td>\n",
              "      <td>116.00</td>\n",
              "      <td>116.00</td>\n",
              "      <td>31.713233</td>\n",
              "      <td>3678.735005</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>2013-04-03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>-0.36038</td>\n",
              "      <td>0.084906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 00:02:00</th>\n",
              "      <td>116.00</td>\n",
              "      <td>116.58</td>\n",
              "      <td>116.00</td>\n",
              "      <td>116.58</td>\n",
              "      <td>2.050985</td>\n",
              "      <td>238.357034</td>\n",
              "      <td>116.215883</td>\n",
              "      <td>2013-04-03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004988</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004988</td>\n",
              "      <td>0.001859</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>-0.36038</td>\n",
              "      <td>0.084906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 00:03:00</th>\n",
              "      <td>116.98</td>\n",
              "      <td>117.00</td>\n",
              "      <td>116.98</td>\n",
              "      <td>117.00</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>2690.890000</td>\n",
              "      <td>116.995217</td>\n",
              "      <td>2013-04-03</td>\n",
              "      <td>0.008413</td>\n",
              "      <td>0.003596</td>\n",
              "      <td>0.008413</td>\n",
              "      <td>0.003596</td>\n",
              "      <td>0.006684</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>-0.36038</td>\n",
              "      <td>0.084906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 00:04:00</th>\n",
              "      <td>117.00</td>\n",
              "      <td>117.00</td>\n",
              "      <td>117.00</td>\n",
              "      <td>117.00</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>5850.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>2013-04-03</td>\n",
              "      <td>0.000171</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000171</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>-0.36038</td>\n",
              "      <td>0.084906</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Open    High     Low  ...        RSI  MACD_index  slow_stoch\n",
              "Time                                         ...                                   \n",
              "2013-04-03 00:00:00  116.00  116.00  116.00  ...  33.333333    -0.36038    0.084906\n",
              "2013-04-03 00:01:00  116.00  116.00  116.00  ...  33.333333    -0.36038    0.084906\n",
              "2013-04-03 00:02:00  116.00  116.58  116.00  ...  33.333333    -0.36038    0.084906\n",
              "2013-04-03 00:03:00  116.98  117.00  116.98  ...  33.333333    -0.36038    0.084906\n",
              "2013-04-03 00:04:00  117.00  117.00  117.00  ...  33.333333    -0.36038    0.084906\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxN7_raMcUSi",
        "colab_type": "text"
      },
      "source": [
        "Dropping Volume Currency as discussed in the Feature Selection phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDc3AcnhcUSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DayTrade = DayTrade.drop(columns='Volume_.Currency.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYfTiUg7cUS0",
        "colab_type": "code",
        "outputId": "b3ef905b-d31a-4ec6-d748-c866aab22a10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "#We need create a target data, which is basically a copy of the data that will be later shifted\n",
        "target_data = DayTrade.copy()\n",
        "target_data = target_data.iloc[:,5:7]\n",
        "target_data.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weighted_Price</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-04-03 00:00:00</th>\n",
              "      <td>116.000000</td>\n",
              "      <td>2013-04-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 00:01:00</th>\n",
              "      <td>116.000000</td>\n",
              "      <td>2013-04-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 00:02:00</th>\n",
              "      <td>116.215883</td>\n",
              "      <td>2013-04-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 00:03:00</th>\n",
              "      <td>116.995217</td>\n",
              "      <td>2013-04-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 00:04:00</th>\n",
              "      <td>117.000000</td>\n",
              "      <td>2013-04-03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Weighted_Price        date\n",
              "Time                                           \n",
              "2013-04-03 00:00:00      116.000000  2013-04-03\n",
              "2013-04-03 00:01:00      116.000000  2013-04-03\n",
              "2013-04-03 00:02:00      116.215883  2013-04-03\n",
              "2013-04-03 00:03:00      116.995217  2013-04-03\n",
              "2013-04-03 00:04:00      117.000000  2013-04-03"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gqzrRLVcUTB",
        "colab_type": "text"
      },
      "source": [
        "The objective of the model is to predict 10 minutes ahead of the current timestep. The Day Trade data contains the minute to minute data for a total of 1735 days. The analysis must be limited within each day."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlV_1_cdcUTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict 10 minutes in the future, although the predictions must be wrapped around each day\n",
        "shift_steps = 10\n",
        "\n",
        "# Now that the target_data was created we need to shift the data so that the target values of 24 hours later aling with our\n",
        "# input data\n",
        "\n",
        "target_data = target_data.groupby('date').shift(-shift_steps)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PabWRzUIcUTV",
        "colab_type": "text"
      },
      "source": [
        "Here we double check that because we shifted the target values now we have NaN values at the end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP86VkS7cUTa",
        "colab_type": "code",
        "outputId": "a7836a33-de0c-4327-b1d0-5cd63c89435d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        }
      },
      "source": [
        "target_data.iloc[1420:1450]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weighted_Price</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:40:00</th>\n",
              "      <td>129.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:41:00</th>\n",
              "      <td>129.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:42:00</th>\n",
              "      <td>129.899861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:43:00</th>\n",
              "      <td>129.892440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:44:00</th>\n",
              "      <td>130.049341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:45:00</th>\n",
              "      <td>131.371316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:46:00</th>\n",
              "      <td>132.534018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:47:00</th>\n",
              "      <td>132.912123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:48:00</th>\n",
              "      <td>132.819273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:49:00</th>\n",
              "      <td>133.091659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:50:00</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:51:00</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:52:00</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:53:00</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:54:00</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:55:00</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:56:00</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:57:00</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:58:00</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:59:00</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-08 00:00:00</th>\n",
              "      <td>164.628270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-08 00:01:00</th>\n",
              "      <td>164.971825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-08 00:02:00</th>\n",
              "      <td>164.990000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-08 00:03:00</th>\n",
              "      <td>164.986254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-08 00:04:00</th>\n",
              "      <td>164.998242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-08 00:05:00</th>\n",
              "      <td>164.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-08 00:06:00</th>\n",
              "      <td>164.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-08 00:07:00</th>\n",
              "      <td>164.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-08 00:08:00</th>\n",
              "      <td>164.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-08 00:09:00</th>\n",
              "      <td>164.960000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Weighted_Price\n",
              "Time                               \n",
              "2013-04-03 23:40:00      129.900000\n",
              "2013-04-03 23:41:00      129.900000\n",
              "2013-04-03 23:42:00      129.899861\n",
              "2013-04-03 23:43:00      129.892440\n",
              "2013-04-03 23:44:00      130.049341\n",
              "2013-04-03 23:45:00      131.371316\n",
              "2013-04-03 23:46:00      132.534018\n",
              "2013-04-03 23:47:00      132.912123\n",
              "2013-04-03 23:48:00      132.819273\n",
              "2013-04-03 23:49:00      133.091659\n",
              "2013-04-03 23:50:00             NaN\n",
              "2013-04-03 23:51:00             NaN\n",
              "2013-04-03 23:52:00             NaN\n",
              "2013-04-03 23:53:00             NaN\n",
              "2013-04-03 23:54:00             NaN\n",
              "2013-04-03 23:55:00             NaN\n",
              "2013-04-03 23:56:00             NaN\n",
              "2013-04-03 23:57:00             NaN\n",
              "2013-04-03 23:58:00             NaN\n",
              "2013-04-03 23:59:00             NaN\n",
              "2013-04-08 00:00:00      164.628270\n",
              "2013-04-08 00:01:00      164.971825\n",
              "2013-04-08 00:02:00      164.990000\n",
              "2013-04-08 00:03:00      164.986254\n",
              "2013-04-08 00:04:00      164.998242\n",
              "2013-04-08 00:05:00      164.960000\n",
              "2013-04-08 00:06:00      164.960000\n",
              "2013-04-08 00:07:00      164.960000\n",
              "2013-04-08 00:08:00      164.960000\n",
              "2013-04-08 00:09:00      164.960000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zBH2un3cUTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we need to remove the rows with NaN values for the target data thus needing to exclude also the \n",
        "# 10 lines per day of the DayTrade data\n",
        "\n",
        "DayTrade['target'] = target_data['Weighted_Price']\n",
        "\n",
        "target_data['date'] = DayTrade['date']\n",
        "\n",
        "DayTrade_clean = DayTrade.dropna()\n",
        "target_data_clean = target_data.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "876etTVLcUTy",
        "colab_type": "code",
        "outputId": "f262ec63-48ea-47f6-ffc0-dffca7392b99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "DayTrade_clean.shape, target_data_clean.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2481050, 16), (2481050, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaFi_FnRcUUK",
        "colab_type": "text"
      },
      "source": [
        "Number of rows for both data are correct since initially the data consisted of 1735 days of 1440 minutes (total of 2.481.050 rows) and now each day had the last 10 minutes so the total amount of rows must be 1735 days of 1430 minutes (total of 2.481.050)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_8nT8cycUUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the target column was only added to the DayTrade data in order to drop the correct rows.\n",
        "#Removing column 'target' from the DayTrade data\n",
        "\n",
        "DayTrade = DayTrade.drop(columns='target')\n",
        "DayTrade_clean = DayTrade_clean.drop(columns='target')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq_qUZNwcUUq",
        "colab_type": "text"
      },
      "source": [
        "## Adding prediction for High and Low based on Daily Summary "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsP1JPiQcUU0",
        "colab_type": "text"
      },
      "source": [
        "The daily summary was used to predict the high and low price of the next day. This values will then be used by the algorithm to try to reduce the variance of the prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7TgM2dmcUU4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "881c4c14-a664-493c-fa83-f222c20edc0d"
      },
      "source": [
        "# Each day of the DayTrade data must have a prediction for what is the current day high and low price expectation\n",
        "\n",
        "#Load DailySummary data\n",
        "file_path = \"/content/drive/My Drive/Capstone/Data Exploration/DSFD.csv\"\n",
        "DaySummary = pd.read_csv(file_path, index_col='date')\n",
        "DaySummary = DaySummary.drop([DaySummary.columns[0]] ,  axis='columns')\n",
        "DaySummary = DaySummary.drop(columns=['Volume_Currency','Close_RoC'])\n",
        "\n",
        "target_dataDaySummary = DaySummary.copy()\n",
        "target_dataDaySummary = target_dataDaySummary.loc[:,['High','Low']]\n",
        "\n",
        "shift_steps = 1\n",
        "target_dataDaySummary = target_dataDaySummary.shift(-shift_steps)\n",
        "\n",
        "DaySummary_clean = DaySummary.iloc[:-1,:]\n",
        "target_dataDaySummary_clean = target_dataDaySummary.iloc[:-1,:]\n",
        "\n",
        "X_data = np.array(DaySummary_clean)\n",
        "Y_data = np.array(target_dataDaySummary_clean)\n",
        "\n",
        "train_split = 0.9\n",
        "\n",
        "n_train_rows = int(X_data.shape[0]*train_split)\n",
        "\n",
        "X_train = X_data[0:n_train_rows]\n",
        "Y_train = Y_data[0:n_train_rows]\n",
        "\n",
        "#Create Scalers and fit them\n",
        "x_scaler = MinMaxScaler()\n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "y_scaler = MinMaxScaler()\n",
        "y_scaler.fit(Y_train)\n",
        "\n",
        "\n",
        "# Scale X_data, rechape and transform it into Batches for prediction\n",
        "X_data_scaled = x_scaler.transform(X_data)\n",
        "X_data_scaled  = X_data_scaled.reshape(1,X_data_scaled.shape[0],X_data_scaled.shape[1])\n",
        "\n",
        "#Create Batches for the X_data\n",
        "sequence_length = 25\n",
        "num_x_signal = 13\n",
        "num_y_signal = 2\n",
        "\n",
        "# Allocate a new array for the batch of input-signals.\n",
        "batch_size_val = X_data_scaled.shape[1] - sequence_length \n",
        "\n",
        "x_shape = (batch_size_val, sequence_length, num_x_signal)\n",
        "x_batch = np.zeros(shape=x_shape, dtype=np.float16)\n",
        "\n",
        "# Fill the batch with random sequences of data.\n",
        "for i in range(batch_size_val):\n",
        "    # Copy the sequences of data starting at this index.\n",
        "    x_batch[i] = X_data_scaled[0][i:i+sequence_length][:]\n",
        "    \n",
        "#load model for prediction \n",
        "DSFD_modelFilePath = \"/content/drive/My Drive/Capstone/FinalModels/Step3-DailySummary/DailySummary_LSTM_trained.h5\"\n",
        "loaded_model = tf.keras.models.load_model(DSFD_modelFilePath)  \n",
        "\n",
        "#Generate the prediction   \n",
        "ypred = loaded_model.predict(x_batch)\n",
        "ypred_rescaled = y_scaler.inverse_transform(ypred)\n",
        "\n",
        "#Create columns of prediction for DaySummary data\n",
        "DaySummary['High_Pred'] = np.nan\n",
        "DaySummary['Low_Pred'] = np.nan\n",
        "\n",
        "\n",
        "#Copy the prediction values to the DauSummary Data\n",
        "DaySummary.High_Pred[26:] =  ypred_rescaled[:,0]\n",
        "DaySummary.Low_Pred[26:] =  ypred_rescaled[:,1]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJDrtTggcUVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now that DaySummary has predictions High and Low predictions for the day, it is necessary to copy those prediction into the \n",
        "# DayTrade data\n",
        "\n",
        "DaySummary_clean = DaySummary.copy()\n",
        "DaySummary_clean.dropna()\n",
        "\n",
        "days_in_DailySummary = list(dict.fromkeys(DaySummary_clean.index.values))\n",
        "days_in_data = list(dict.fromkeys(DayTrade_clean[\"date\"].values))\n",
        "days_with_predictions = list(set(days_in_data).intersection(days_in_DailySummary))\n",
        "\n",
        "DayTrade_clean['High_Pred'] = np.nan\n",
        "DayTrade_clean['Low_Pred'] = np.nan\n",
        "\n",
        "for day in days_with_predictions:\n",
        "    DayTrade_clean.High_Pred[DayTrade_clean['date'].values==day] = np.array(DaySummary_clean.High_Pred[DaySummary_clean.index==day])\n",
        "    DayTrade_clean.Low_Pred[DayTrade_clean['date'].values==day] = np.array(DaySummary_clean.Low_Pred[DaySummary_clean.index==day])    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqtNi3UPcUVO",
        "colab_type": "code",
        "outputId": "85a1817e-60dd-44bb-c422-0a570c1bff6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "DayTrade_clean = DayTrade_clean.dropna()\n",
        "DayTrade_clean.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2453880, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHnCFlbT2CVB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "bcd281c8-1f2d-4a78-994d-dd67007b538b"
      },
      "source": [
        "DayTrade_clean.columns"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Open', 'High', 'Low', 'Close', 'Volume_.BTC.', 'Weighted_Price',\n",
              "       'date', 'Open_RoC', 'High_RoC', 'Low_RoC', 'Close_RoC',\n",
              "       'Weighted_Price_RoC', 'RSI', 'MACD_index', 'slow_stoch', 'High_Pred',\n",
              "       'Low_Pred'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGYBhkpp3MHc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "9d15f59e-7007-4d81-ffeb-07ccbfe898ca"
      },
      "source": [
        "DayTrade_clean.tail(10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume_.BTC.</th>\n",
              "      <th>Weighted_Price</th>\n",
              "      <th>date</th>\n",
              "      <th>Open_RoC</th>\n",
              "      <th>High_RoC</th>\n",
              "      <th>Low_RoC</th>\n",
              "      <th>Close_RoC</th>\n",
              "      <th>Weighted_Price_RoC</th>\n",
              "      <th>RSI</th>\n",
              "      <th>MACD_index</th>\n",
              "      <th>slow_stoch</th>\n",
              "      <th>High_Pred</th>\n",
              "      <th>Low_Pred</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-08-11 23:40:00</th>\n",
              "      <td>11528.20</td>\n",
              "      <td>11532.86</td>\n",
              "      <td>11505.84</td>\n",
              "      <td>11505.97</td>\n",
              "      <td>2.049550</td>\n",
              "      <td>11527.942145</td>\n",
              "      <td>2019-08-11</td>\n",
              "      <td>0.000680</td>\n",
              "      <td>0.001084</td>\n",
              "      <td>-0.000536</td>\n",
              "      <td>-0.000525</td>\n",
              "      <td>0.001007</td>\n",
              "      <td>46.910718</td>\n",
              "      <td>0.005368</td>\n",
              "      <td>0.436299</td>\n",
              "      <td>11879.370117</td>\n",
              "      <td>11216.633789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-11 23:41:00</th>\n",
              "      <td>11522.45</td>\n",
              "      <td>11522.45</td>\n",
              "      <td>11519.16</td>\n",
              "      <td>11519.16</td>\n",
              "      <td>3.455912</td>\n",
              "      <td>11521.067360</td>\n",
              "      <td>2019-08-11</td>\n",
              "      <td>-0.000499</td>\n",
              "      <td>-0.000903</td>\n",
              "      <td>0.001157</td>\n",
              "      <td>0.001146</td>\n",
              "      <td>-0.000597</td>\n",
              "      <td>53.438167</td>\n",
              "      <td>0.005437</td>\n",
              "      <td>0.414254</td>\n",
              "      <td>11879.370117</td>\n",
              "      <td>11216.633789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-11 23:42:00</th>\n",
              "      <td>11522.10</td>\n",
              "      <td>11524.83</td>\n",
              "      <td>11522.10</td>\n",
              "      <td>11524.83</td>\n",
              "      <td>0.220695</td>\n",
              "      <td>11522.285170</td>\n",
              "      <td>2019-08-11</td>\n",
              "      <td>-0.000030</td>\n",
              "      <td>0.000207</td>\n",
              "      <td>0.000255</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.000106</td>\n",
              "      <td>55.945707</td>\n",
              "      <td>0.007044</td>\n",
              "      <td>0.458960</td>\n",
              "      <td>11879.370117</td>\n",
              "      <td>11216.633789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-11 23:43:00</th>\n",
              "      <td>11519.26</td>\n",
              "      <td>11519.26</td>\n",
              "      <td>11510.00</td>\n",
              "      <td>11510.00</td>\n",
              "      <td>5.479156</td>\n",
              "      <td>11510.019621</td>\n",
              "      <td>2019-08-11</td>\n",
              "      <td>-0.000247</td>\n",
              "      <td>-0.000483</td>\n",
              "      <td>-0.001051</td>\n",
              "      <td>-0.001288</td>\n",
              "      <td>-0.001065</td>\n",
              "      <td>48.577001</td>\n",
              "      <td>0.007458</td>\n",
              "      <td>0.524607</td>\n",
              "      <td>11879.370117</td>\n",
              "      <td>11216.633789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-11 23:44:00</th>\n",
              "      <td>11518.83</td>\n",
              "      <td>11533.19</td>\n",
              "      <td>11518.83</td>\n",
              "      <td>11518.83</td>\n",
              "      <td>0.301245</td>\n",
              "      <td>11521.713463</td>\n",
              "      <td>2019-08-11</td>\n",
              "      <td>-0.000037</td>\n",
              "      <td>0.001209</td>\n",
              "      <td>0.000767</td>\n",
              "      <td>0.000767</td>\n",
              "      <td>0.001015</td>\n",
              "      <td>52.581741</td>\n",
              "      <td>0.008309</td>\n",
              "      <td>0.573885</td>\n",
              "      <td>11879.370117</td>\n",
              "      <td>11216.633789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-11 23:45:00</th>\n",
              "      <td>11518.00</td>\n",
              "      <td>11525.85</td>\n",
              "      <td>11518.00</td>\n",
              "      <td>11525.85</td>\n",
              "      <td>0.037464</td>\n",
              "      <td>11518.097327</td>\n",
              "      <td>2019-08-11</td>\n",
              "      <td>-0.000072</td>\n",
              "      <td>-0.000637</td>\n",
              "      <td>-0.000072</td>\n",
              "      <td>0.000609</td>\n",
              "      <td>-0.000314</td>\n",
              "      <td>55.545825</td>\n",
              "      <td>0.010345</td>\n",
              "      <td>0.585729</td>\n",
              "      <td>11879.370117</td>\n",
              "      <td>11216.633789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-11 23:46:00</th>\n",
              "      <td>11525.85</td>\n",
              "      <td>11545.00</td>\n",
              "      <td>11525.85</td>\n",
              "      <td>11536.46</td>\n",
              "      <td>2.692778</td>\n",
              "      <td>11532.658016</td>\n",
              "      <td>2019-08-11</td>\n",
              "      <td>0.000681</td>\n",
              "      <td>0.001660</td>\n",
              "      <td>0.000681</td>\n",
              "      <td>0.000920</td>\n",
              "      <td>0.001263</td>\n",
              "      <td>59.651077</td>\n",
              "      <td>0.014460</td>\n",
              "      <td>0.635066</td>\n",
              "      <td>11879.370117</td>\n",
              "      <td>11216.633789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-11 23:47:00</th>\n",
              "      <td>11537.75</td>\n",
              "      <td>11539.04</td>\n",
              "      <td>11537.75</td>\n",
              "      <td>11539.04</td>\n",
              "      <td>1.353892</td>\n",
              "      <td>11538.087191</td>\n",
              "      <td>2019-08-11</td>\n",
              "      <td>0.001032</td>\n",
              "      <td>-0.000516</td>\n",
              "      <td>0.001032</td>\n",
              "      <td>0.000224</td>\n",
              "      <td>0.000471</td>\n",
              "      <td>60.603809</td>\n",
              "      <td>0.019988</td>\n",
              "      <td>0.713420</td>\n",
              "      <td>11879.370117</td>\n",
              "      <td>11216.633789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-11 23:48:00</th>\n",
              "      <td>11535.84</td>\n",
              "      <td>11544.18</td>\n",
              "      <td>11531.55</td>\n",
              "      <td>11532.27</td>\n",
              "      <td>0.369848</td>\n",
              "      <td>11532.563833</td>\n",
              "      <td>2019-08-11</td>\n",
              "      <td>-0.000166</td>\n",
              "      <td>0.000445</td>\n",
              "      <td>-0.000538</td>\n",
              "      <td>-0.000587</td>\n",
              "      <td>-0.000479</td>\n",
              "      <td>56.812934</td>\n",
              "      <td>0.025128</td>\n",
              "      <td>0.779253</td>\n",
              "      <td>11879.370117</td>\n",
              "      <td>11216.633789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-11 23:49:00</th>\n",
              "      <td>11542.17</td>\n",
              "      <td>11550.00</td>\n",
              "      <td>11541.23</td>\n",
              "      <td>11541.23</td>\n",
              "      <td>5.850044</td>\n",
              "      <td>11546.420199</td>\n",
              "      <td>2019-08-11</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>0.000504</td>\n",
              "      <td>0.000839</td>\n",
              "      <td>0.000777</td>\n",
              "      <td>0.001201</td>\n",
              "      <td>60.348083</td>\n",
              "      <td>0.030938</td>\n",
              "      <td>0.793625</td>\n",
              "      <td>11879.370117</td>\n",
              "      <td>11216.633789</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Open      High  ...     High_Pred      Low_Pred\n",
              "Time                                     ...                            \n",
              "2019-08-11 23:40:00  11528.20  11532.86  ...  11879.370117  11216.633789\n",
              "2019-08-11 23:41:00  11522.45  11522.45  ...  11879.370117  11216.633789\n",
              "2019-08-11 23:42:00  11522.10  11524.83  ...  11879.370117  11216.633789\n",
              "2019-08-11 23:43:00  11519.26  11519.26  ...  11879.370117  11216.633789\n",
              "2019-08-11 23:44:00  11518.83  11533.19  ...  11879.370117  11216.633789\n",
              "2019-08-11 23:45:00  11518.00  11525.85  ...  11879.370117  11216.633789\n",
              "2019-08-11 23:46:00  11525.85  11545.00  ...  11879.370117  11216.633789\n",
              "2019-08-11 23:47:00  11537.75  11539.04  ...  11879.370117  11216.633789\n",
              "2019-08-11 23:48:00  11535.84  11544.18  ...  11879.370117  11216.633789\n",
              "2019-08-11 23:49:00  11542.17  11550.00  ...  11879.370117  11216.633789\n",
              "\n",
              "[10 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seuxLwmi3SQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DayTrade_clean.to_csv('/content/drive/My Drive/Capstone/FinalModels/Step4-DayTrade_DailySummaryInputs/DayTrade_clean.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeTGWr0IAXtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DayTrade_clean = pd.read_csv('/content/drive/My Drive/Capstone/FinalModels/Step4-DayTrade_DailySummaryInputs/DayTrade_clean.csv', index_col='Time')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QARSmHyKcUVc",
        "colab_type": "text"
      },
      "source": [
        "By adding the High and Low predictions from the Daily Summary data and removing the NaN the data now has 2.453.880 rows (which corresponds to 1716 days), which means 19 days of the original data lied before the 25 first days that the Daily Summary data needed to begin making predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHAbwIhTcUVf",
        "colab_type": "text"
      },
      "source": [
        "## Continuing with Day Trade Analysis "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fz9_o3BcUVh",
        "colab_type": "text"
      },
      "source": [
        "In order to compare results with other models the same dates for testing must be used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45Dc-RCkcUVk",
        "colab_type": "code",
        "outputId": "abfddddd-33b5-438f-b478-5b21d03048bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Previous algorithm used 174 days for testing\n",
        "days_in_data = list(dict.fromkeys(DayTrade_clean[\"date\"].values))\n",
        "\n",
        "training_days = days_in_data[:len(days_in_data)-174]\n",
        "testing_days = days_in_data[len(days_in_data)-174:]\n",
        "\n",
        "print(len(training_days),len(testing_days))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1542 174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOgX6izscUVs",
        "colab_type": "text"
      },
      "source": [
        "Data will need to be normalized for predictions. A scaler will be fitted for the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIPe-9dwcUVu",
        "colab_type": "code",
        "outputId": "081478be-289a-4655-8040-81a706f2f2c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#Step 1 - Convert day data into numpy array\n",
        "train_data = np.array(DayTrade_clean.loc[DayTrade_clean.date.isin(training_days),:].drop(columns='date'))\n",
        "label_data = np.array(target_data_clean.loc[target_data_clean.date.isin(training_days),:].drop(columns='date')).reshape(-1,1)\n",
        "\n",
        "#Step 2 - Scale data for Neural Network\n",
        "x_scaler = MinMaxScaler()\n",
        "x_scaler.fit(train_data)\n",
        "y_scaler = MinMaxScaler()\n",
        "y_scaler.fit(label_data)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler(copy=True, feature_range=(0, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp11hzjlcUV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_reshape(sequence_length, X_train_scale, Y_train_scale, num_x_signal, num_y_signal):\n",
        "    \"\"\"\n",
        "    Generator function for creating random batches of training-data.\n",
        "    \"\"\"\n",
        "    batch_size = X_train_scale.shape[1] // sequence_length\n",
        "    # Allocate a new array for the batch of input-signals.\n",
        "    x_shape = (batch_size, sequence_length, num_x_signal)\n",
        "    x_batch = np.zeros(shape=x_shape, dtype=np.float16)\n",
        "    \n",
        " \n",
        "    # Allocate a new array for the batch of output-signals.\n",
        "    y_shape = (batch_size, num_y_signal)\n",
        "    y_batch = np.zeros(shape=y_shape, dtype=np.float16)\n",
        "\n",
        "    #print(x_batch.shape, y_batch.shape, X_train_scale.shape, Y_train_scale.shape) #debugging\n",
        "    # Create Sequence for sliding window\n",
        "    seq = []\n",
        "    for i in range(batch_size):\n",
        "        seq.append(i*sequence_length)\n",
        "    \n",
        "    # Fill the batch with sequences of data.\n",
        "    for i in range(0,len(seq)-1):\n",
        "\n",
        "        # Copy the sequences of data starting at this index.\n",
        "        x_batch[i] = X_train_scale[0][seq[i]:seq[i]+sequence_length][:]\n",
        "        y_batch[i] = Y_train_scale[0][seq[i]+sequence_length-1][:]\n",
        "        #print(\"iteration: \",i,\"-OK\") #debugging\n",
        "\n",
        "    #print(x_batch.shape,y_batch.shape) #debbuging\n",
        "    return (x_batch, y_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqAUptx1cUV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_generator(batch_size, sequence_length, num_x_signal, num_y_signal, train_data, label_data, training_days):\n",
        "    \n",
        "    # Create a Batch function for training data using sliding window technique\n",
        "    # Step 1 - Select a training day\n",
        "\n",
        "    day = rand.choice(training_days)\n",
        "\n",
        "    #Step 2 - Filter Input data and Target with the selected date\n",
        "    day_train_data = train_data[train_data['date'].values==day]\n",
        "    day_label_data = label_data[label_data['date'].values==day]\n",
        "\n",
        "    #Step 3 - Drop date columns from day train data and day label data\n",
        "    day_train_data = day_train_data.drop(columns='date')\n",
        "    day_label_data = day_label_data.drop(columns='date')\n",
        "\n",
        "    #Step 4 - Convert day data into numpy array\n",
        "    day_train_data = np.array(day_train_data)\n",
        "    day_label_data = np.array(day_label_data).reshape(-1,1)\n",
        "\n",
        "    #Step 5 - Scale data for Neural Network\n",
        "    day_train_data = x_scaler.transform(day_train_data)\n",
        "    day_label_data = y_scaler.transform(day_label_data)\n",
        "\n",
        "    #Step 6 - Reshape data to fit keras requirement to have a (x,y,z) shape\n",
        "    day_train_data = day_train_data.reshape(1,day_train_data.shape[0],day_train_data.shape[1])\n",
        "    day_label_data = day_label_data.reshape(1,day_label_data.shape[0],day_label_data.shape[1])\n",
        "    \n",
        "     #Step 7 - Reshape data into Batches\n",
        "    day_train_data_reshape , day_label_data_reshape =  batch_reshape(sequence_length, day_train_data, day_label_data, num_x_signal, num_y_signal)\n",
        "    \n",
        "    # print(day_train_data_reshape.shape , day_train_data_reshape.shape)#debugging\n",
        "   \n",
        "    #Step 8 - Apply the \"jumping\" slidding window technique to the reshaped date\n",
        "    # Infinite loop.\n",
        "    while True:\n",
        "        # Allocate a new array for the batch of input-signals.\n",
        "        x_shape = (batch_size, sequence_length, num_x_signal)\n",
        "        x_batch = np.zeros(shape=x_shape, dtype=np.float16)\n",
        "\n",
        "        # Allocate a new array for the batch of output-signals.\n",
        "        y_shape = (batch_size, num_y_signal)\n",
        "        y_batch = np.zeros(shape=y_shape, dtype=np.float16)\n",
        "\n",
        "        # Fill the batch with random continuous sequences of data.\n",
        "\n",
        "        # Get a random start-index.\n",
        "        # This points somewhere into the training-data.\n",
        "        idx = np.random.randint(day_train_data_reshape.shape[0] - batch_size)\n",
        "\n",
        "        # Copy the sequences of data starting at this index.\n",
        "        x_batch = day_train_data_reshape[idx:idx+batch_size]\n",
        "        y_batch = day_label_data_reshape[idx:idx+batch_size]\n",
        "\n",
        "\n",
        "        yield (x_batch, y_batch)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrBCLFiocUWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_x_signal = 16 # number of input features\n",
        "num_y_signal = 1 # number of label classes\n",
        "\n",
        "batch_size = 50 # tunning parameter\n",
        "sequence_length = 25 #Amount of time-steps to look back for the 10 minute prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcUBg8DJcUWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = batch_generator(batch_size,sequence_length, num_x_signal, num_y_signal, DayTrade_clean, target_data_clean,training_days)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e20qDTDZcUWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_batch, y_batch = next(generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNAD0wbrcUW4",
        "colab_type": "code",
        "outputId": "2c46bdd7-4dd3-48ec-e848-7544c2fd0bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(x_batch.shape)\n",
        "print(y_batch.shape)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 25, 16)\n",
            "(50, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HcId0fVcUXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def batch_validation(sequence_length, num_x_signal, num_y_signal, test_data, label_test_data, testing_days):\n",
        "    \n",
        "    # Create a Batch function for validation data using sliding window technique\n",
        "    # Step 1 - Select a testing day\n",
        "\n",
        "    day = rand.choice(testing_days)\n",
        "\n",
        "    #Step 2 - Filter Input data and Target with the selected date\n",
        "    day_test_data = test_data[test_data['date'].values==day]\n",
        "    day_label_data = label_test_data[label_test_data['date'].values==day]\n",
        "\n",
        "    #Step 3 - Drop date columns from day test data and day label data\n",
        "    day_test_data = day_test_data.drop(columns='date')\n",
        "    day_label_data = day_label_data.drop(columns='date')\n",
        "\n",
        "    #Step 4 - Convert day data into numpy array\n",
        "    day_test_data = np.array(day_test_data)\n",
        "    day_label_data = np.array(day_label_data).reshape(-1,1)\n",
        "\n",
        "    #Step 5 - Scale data for Neural Network\n",
        "    day_test_data = x_scaler.transform(day_test_data)\n",
        "    day_label_data = y_scaler.transform(day_label_data)\n",
        "\n",
        "    #Step 6 - Reshape data to fit keras requirement to have a (x,y,z) shape\n",
        "    day_test_data = day_test_data.reshape(1,day_test_data.shape[0],day_test_data.shape[1])\n",
        "    day_label_data = day_label_data.reshape(1,day_label_data.shape[0],day_label_data.shape[1])\n",
        "    \n",
        "    #print(day_test_data.shape , day_label_data.shape)#debugging\n",
        "    \n",
        "    #Step 7 - Reshape data into Batches using slidding window   \n",
        "    batch_val_size = day_test_data.shape[1] - sequence_length\n",
        "    \n",
        "    x_val_shape = (batch_val_size, sequence_length, num_x_signal)\n",
        "    x_batch = np.zeros(shape=x_val_shape, dtype=np.float16)\n",
        "        \n",
        "    y_val_shape = (batch_val_size, num_y_signal)\n",
        "    y_batch = np.zeros(shape=y_val_shape, dtype=np.float16)\n",
        "    \n",
        "    #print(x_batch.shape, y_batch.shape) # debugging\n",
        "    for i in range(batch_val_size):\n",
        "\n",
        "        # Copy the sequences of data starting at this index.\n",
        "        x_batch[i] = day_test_data[0][i:i+sequence_length][:]\n",
        "        y_batch[i] = day_label_data[0][i+sequence_length-1][:]\n",
        "\n",
        "    \n",
        "    return (x_batch, y_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm574sBxcUXN",
        "colab_type": "code",
        "outputId": "4400a723-ecfd-448c-8ff5-8180c1f4a23b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "X_val, Y_val = batch_validation(sequence_length,num_x_signal, num_y_signal, DayTrade_clean, target_data_clean, testing_days)\n",
        "print(X_val.shape, Y_val.shape)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1405, 25, 16) (1405, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWbRxaZycUXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_data = (X_val, Y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT3Rc3ffcUXs",
        "colab_type": "text"
      },
      "source": [
        "## Create Recurrent Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SbFQa1xcUXy",
        "colab_type": "code",
        "outputId": "68e404ad-82f0-49bb-d4d2-5508f9c795dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=200,\n",
        "              return_sequences=True,\n",
        "              input_shape=(None,num_x_signal,)))\n",
        "model.add(LSTM(units=150, return_sequences=False))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(num_y_signal,activation='linear'))\n",
        "model.summary()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_10 (LSTM)               (None, None, 200)         173600    \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 150)               210600    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 150)               600       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 151       \n",
            "=================================================================\n",
            "Total params: 384,951\n",
            "Trainable params: 384,651\n",
            "Non-trainable params: 300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4I_NPSscUYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(lr=1e-3)\n",
        "\n",
        "model.compile(loss=tf.keras.losses.logcosh, optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCizhpRZcUYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_file = \"DayTrade with DailySummary Model(seed 10).{epoch:02d}-{val_loss:.4f}.h5\"\n",
        "\n",
        "mc = ModelCheckpoint('/content/drive/My Drive/Capstone/FinalModels/Step4-DayTrade_DailySummaryInputs/Seed 10/'+model_file, monitor=\"val_loss\", mode=\"min\", save_best_only=True)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=4, min_lr=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Csq6lk56cUYr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a01fb63-7a34-4b61-cdb0-93c32a02ad00"
      },
      "source": [
        "%%time\n",
        "\n",
        "history = model.fit_generator(generator=generator,\n",
        "                    epochs=100,\n",
        "                    steps_per_epoch=50,\n",
        "                    validation_data=validation_data,\n",
        "                    callbacks=[ mc, reduce_lr])\n",
        "                    #callbacks=[es, reduce_lr])"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.3004 - val_loss: 0.0802 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 0.0480 - val_loss: 0.0834 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 9s 170ms/step - loss: 0.0057 - val_loss: 0.0767 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 0.0023 - val_loss: 0.0763 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 0.0014 - val_loss: 0.0695 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 9.3435e-04 - val_loss: 0.0704 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 7.5363e-04 - val_loss: 0.0646 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 7.0746e-04 - val_loss: 0.0573 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 7.0364e-04 - val_loss: 0.0512 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 8s 165ms/step - loss: 5.1712e-04 - val_loss: 0.0459 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 5.6008e-04 - val_loss: 0.0279 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 5.6317e-04 - val_loss: 0.0210 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 8s 167ms/step - loss: 5.1111e-04 - val_loss: 0.0168 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 8s 167ms/step - loss: 6.2276e-04 - val_loss: 0.0063 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 8s 166ms/step - loss: 5.8813e-04 - val_loss: 1.8234e-04 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 8s 166ms/step - loss: 6.9767e-04 - val_loss: 5.0599e-04 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 5.9141e-04 - val_loss: 0.0049 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 6.7623e-04 - val_loss: 3.6927e-04 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 9s 171ms/step - loss: 4.9599e-04 - val_loss: 6.7465e-05 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 5.5125e-04 - val_loss: 0.0037 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 5.9644e-04 - val_loss: 0.0023 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 5.9254e-04 - val_loss: 9.7673e-04 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 6.1288e-04 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 8s 161ms/step - loss: 2.2767e-04 - val_loss: 0.0050 - lr: 2.0000e-04\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 5.9638e-05 - val_loss: 0.0053 - lr: 2.0000e-04\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 4.6505e-05 - val_loss: 0.0051 - lr: 2.0000e-04\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 4.2384e-05 - val_loss: 0.0055 - lr: 2.0000e-04\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 8s 161ms/step - loss: 3.9721e-05 - val_loss: 0.0051 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 4.0817e-05 - val_loss: 0.0053 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 3.6677e-05 - val_loss: 0.0045 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 3.4452e-05 - val_loss: 0.0046 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 3.4876e-05 - val_loss: 0.0044 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 8s 161ms/step - loss: 3.3897e-05 - val_loss: 0.0052 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 3.2397e-05 - val_loss: 0.0054 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 3.3397e-05 - val_loss: 0.0048 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 3.2264e-05 - val_loss: 0.0052 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 3.1401e-05 - val_loss: 0.0047 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 3.3749e-05 - val_loss: 0.0049 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 3.3347e-05 - val_loss: 0.0044 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 3.1093e-05 - val_loss: 0.0046 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 8s 166ms/step - loss: 3.0685e-05 - val_loss: 0.0043 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 3.1560e-05 - val_loss: 0.0046 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 3.1226e-05 - val_loss: 0.0051 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 3.0146e-05 - val_loss: 0.0046 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 3.0446e-05 - val_loss: 0.0043 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 8s 161ms/step - loss: 2.9323e-05 - val_loss: 0.0051 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 2.8948e-05 - val_loss: 0.0042 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 3.0777e-05 - val_loss: 0.0051 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 2.9397e-05 - val_loss: 0.0048 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 2.9933e-05 - val_loss: 0.0051 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 3.0971e-05 - val_loss: 0.0052 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 3.1946e-05 - val_loss: 0.0045 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 2.9811e-05 - val_loss: 0.0046 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 2.9162e-05 - val_loss: 0.0040 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 2.8199e-05 - val_loss: 0.0043 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 2.9430e-05 - val_loss: 0.0043 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 2.7285e-05 - val_loss: 0.0039 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 2.8722e-05 - val_loss: 0.0043 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 2.7649e-05 - val_loss: 0.0049 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 2.9088e-05 - val_loss: 0.0040 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 2.7780e-05 - val_loss: 0.0040 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 3.0887e-05 - val_loss: 0.0040 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 2.5655e-05 - val_loss: 0.0032 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 2.8618e-05 - val_loss: 0.0039 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 2.6467e-05 - val_loss: 0.0030 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 2.5443e-05 - val_loss: 0.0031 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 2.6841e-05 - val_loss: 0.0034 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 2.6830e-05 - val_loss: 0.0025 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 3.0995e-05 - val_loss: 0.0029 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 8s 165ms/step - loss: 2.5929e-05 - val_loss: 0.0034 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 2.7187e-05 - val_loss: 0.0030 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 8s 166ms/step - loss: 2.5843e-05 - val_loss: 0.0027 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 2.7551e-05 - val_loss: 0.0030 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 2.7197e-05 - val_loss: 0.0027 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 2.6448e-05 - val_loss: 0.0029 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 2.6746e-05 - val_loss: 0.0035 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 2.6689e-05 - val_loss: 0.0032 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 2.6623e-05 - val_loss: 0.0019 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 8s 166ms/step - loss: 2.4411e-05 - val_loss: 0.0025 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 8s 165ms/step - loss: 2.7233e-05 - val_loss: 0.0019 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 8s 165ms/step - loss: 2.7455e-05 - val_loss: 0.0024 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 2.7152e-05 - val_loss: 0.0032 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 2.7080e-05 - val_loss: 0.0032 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 2.7415e-05 - val_loss: 0.0026 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 3.0061e-05 - val_loss: 0.0022 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 2.8642e-05 - val_loss: 0.0029 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 2.9828e-05 - val_loss: 0.0021 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 2.9271e-05 - val_loss: 0.0022 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 3.0634e-05 - val_loss: 0.0018 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 8s 165ms/step - loss: 3.1440e-05 - val_loss: 0.0016 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 9s 183ms/step - loss: 2.6517e-05 - val_loss: 0.0014 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 3.0975e-05 - val_loss: 0.0011 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 3.0514e-05 - val_loss: 0.0014 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 3.0206e-05 - val_loss: 0.0026 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 2.8519e-05 - val_loss: 0.0021 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 3.0443e-05 - val_loss: 0.0031 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 2.6883e-05 - val_loss: 0.0022 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 2.6052e-05 - val_loss: 0.0016 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 2.5863e-05 - val_loss: 0.0012 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 8s 166ms/step - loss: 3.3471e-05 - val_loss: 0.0015 - lr: 1.0000e-04\n",
            "CPU times: user 22min 41s, sys: 1min 27s, total: 24min 8s\n",
            "Wall time: 13min 57s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm_LpGX8cUYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "hist_df = pd.DataFrame(history.history) \n",
        "hist_csv_file = '/content/drive/My Drive/Capstone/FinalModels/Step4-DayTrade_DailySummaryInputs/Seed 10/'+model_file.split('.')[0]+'.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZrvzgFdcUZD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "96b80c55-274e-4bd4-fa00-c6e05bb23a19"
      },
      "source": [
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model_loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFBAiIhLW/w/a/f4c1My2qAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Nngbf4FcUZM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "8d1d6b6b-74bf-42f6-d307-8073cfeb6da4"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('model_loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAfu0lEQVR4nO3de5RdZZ3m8e9zLkklEEIIxS0BEjVi\ngpcgRaQbtVmKGAUJ06IEGwcdRsYZWWprOwZ10KbHtVB72V5AIbaZRluJCNKT7o5NA4LdLgFTXBpI\nIEOIkVTkEhISArnV5Td/7PdU7SpPJZWq2qnknOezVlbOvp3z7tpJPed93/2+WxGBmZnZQKWxLoCZ\nmR2YHBBmZlaXA8LMzOpyQJiZWV0OCDMzq8sBYWZmdTkgzMysLgeE2QhI+jtJ/3uI+66TdNZe9vmS\npL8fndKZjYwDwszM6nJAmJlZXQ4Iawqpeeczkh6W9LKk70s6WtLPJW2TdIekKWnf8yStlLRF0t2S\nZufe5xRJD6RjfgK0DPiccyU9lI79taTXj7DceyrLZyVtSGVZLentaf08Se2SXpT0rKSvj6QM1rwc\nENZM3gu8A3g18B7g58DngFay/wsfl/Rq4Ebgk2n9cuAfJY2TNA74B+CHwBHAT9N7All4AEuA/wZM\nBa4HlkkaP5zC7qUsJwGXA6dFxCTgncC6dOg3gW9GxGHAK4GbhvP5Zg4IaybfjohnI2ID8O/AfRHx\nYETsBG4FTgEuBP45Im6PiE7gr4EJwB8DpwNV4BsR0RkRNwMrcu9/GXB9RNwXEd0RcQOwKx03HHsq\nSzcwHpgjqRoR6yLiyXRcJ/AqSUdGxEsRce8wP9+anAPCmsmzudc76iwfChwH/K62MiJ6gPXAtLRt\nQ/SfAvl3udcnAp9OzUFbJG0Bjk/HDcegZYmINWQ1iy8Bz0laKqn2OZeS1ZIel7RC0rnD/Hxrcg4I\ns/5+T/aLHgBJIvslvwF4GpiW1tWckHu9HvhyRBye+zMxIm4soCxExI8j4s1pnwC+ktY/EREXAUel\ndTdLOmSYZbAm5oAw6+8m4BxJb5dUBT5N1kz0a+AeoIusr6Iq6U+Bebljvwd8VNKblDlE0jmSJo12\nWSSdJOltqX9jJ1kNqAdA0sWSWlONY0t6r55hlsGamAPCLCciVgMXA98GnifrzH5PROyOiN3AnwIf\nAjaT9RH8LHdsO/AR4BrgBWBN2nfUy0LW/3B1Wv8MWW3hinTofGClpJfIOqwXRsSO4ZbDmpf8RDkz\nM6vHNQgzM6vLAWG2n6XBeS/V+fO5sS6bWZ6bmMzMrK7KWBdgtBx55JExY8aMsS6GmdlB5f77738+\nIlrrbWuYgJgxYwbt7e1jXQwzs4OKpN8Nts19EGZmVpcDwszM6nJAmJlZXQ3TB1FPZ2cnHR0d7Ny5\nc6yLUriWlhamT59OtVod66KYWYNo6IDo6Ohg0qRJzJgxg/7zqzWWiGDTpk10dHQwc+bMsS6OmTWI\nQpuYJM1PT7paI2lRne0flfRIegLXryTNyW27Ih23WtI7h/P5O3fuZOrUqQ0dDgCSmDp1alPUlMxs\n/yksICSVgWuBdwFzgIvyAZD8OCJeFxFzga8CX0/HzgEWAieTTTz2nfR+wynHMM/g4NIs52lm+0+R\nNYh5wJqIWJtmn1wKLMjvEBEv5hYPIZvTnrTf0ojYFRG/JZsVMz+t8qjp7gme2bqT7bu7inh7M7OD\nVpEBMY3sASo1HWldP5I+JulJshrEx/fl2NEQETy3bSfbd3cX8fZs2bKF73znO/t83Lvf/W62bNmy\n9x3NzAoy5re5RsS1EfFK4LPAF/blWEmXSWqX1L5x48ZhfX6tZaaoKakGC4iurj3XWJYvX87hhx9e\nTKHMzIagyIDYQPZ4xJrpad1glgLn78uxEbE4Itoioq21te5UIkNQa7svJiEWLVrEk08+ydy5cznt\ntNN4y1vewnnnncecOVl3zPnnn8+pp57KySefzOLFi3uPmzFjBs8//zzr1q1j9uzZfOQjH+Hkk0/m\n7LPPZscOP/vFzIpX5G2uK4BZkmaS/XJfCHwgv4OkWRHxRFo8B6i9Xgb8WNLXyR7cPgv4zUgK85f/\nuJJVv3+x7raXd3UxrlKiWt63vJxz3GF88T0n73Gfq6++mkcffZSHHnqIu+++m3POOYdHH32093bU\nJUuWcMQRR7Bjxw5OO+003vve9zJ16tR+7/HEE09w44038r3vfY/3v//93HLLLVx88cX7VFYzs31V\nWEBERJeky4HbgDKwJCJWSroKaI+IZcDlks4COske0XhJOnalpJuAVWTPAP5YRBTTSbCfzZs3r99Y\nhW9961vceuutAKxfv54nnnjiDwJi5syZzJ07F4BTTz2VdevW7bfymlnzKnSgXEQsB5YPWHdl7vUn\n9nDsl4Evj1ZZ9vRN/5GOrbROGs8xk1tG6+MGdcghh/S+vvvuu7njjju45557mDhxImeeeWbdsQzj\nx4/vfV0ul93EZGb7xZh3Uh8QBFFQH8SkSZPYtm1b3W1bt25lypQpTJw4kccff5x77723kDKYmQ1H\nQ0+1MVSiuLuYpk6dyhlnnMFrX/taJkyYwNFHH927bf78+Vx33XXMnj2bk046idNPP72YQpiZDUPD\nPHK0ra0tBj4w6LHHHmP27Nl7PXbl77cyZeI4jjt8QlHF2y+Ger5mZjWS7o+Itnrb3MQECNEoQWlm\nNlocEGSD5RwPZmb9NXxADKVmUGQfxP7iGpCZjbaGDoiWlhY2bdq011+eB3sNovY8iJaW4m/TNbPm\n0dB3MU2fPp2Ojg72Nk/Tsy/upFou8fKz4/ZTyUZf7YlyZmajpaEDolqtDukJa3/+jX/jxKkTuf6D\nb9gPpTIzOzg0dBPTUFXKoqv7YG5kMjMbfQ4IoFIq0dnjgDAzy3NAAJWS6O7pGetimJkdUBwQZE1M\nnW5iMjPrxwEBVMslurpdgzAzy3NAkDUxdbkPwsysHwcEUC6VfBeTmdkADgigWhZd7qQ2M+vHAQFU\nyq5BmJkN5IAg64PodA3CzKwfBwRpHIRrEGZm/TggyJqYPJLazKw/BwSpk9rjIMzM+nFAAGWPgzAz\n+wMOCGojqR0QZmZ5hQaEpPmSVktaI2lRne2fkrRK0sOS7pR0Ym5bt6SH0p9lRZYzG0ntJiYzs7zC\nHhgkqQxcC7wD6ABWSFoWEatyuz0ItEXEdkn/HfgqcGHatiMi5hZVvrxKuURndxARSNofH2lmdsAr\nsgYxD1gTEWsjYjewFFiQ3yEi7oqI7WnxXmBMnplZKWWh4G4IM7M+RQbENGB9brkjrRvMpcDPc8st\nktol3Svp/HoHSLos7dO+t+dO70mlnAVEp+9kMjPrdUA8k1rSxUAb8Ce51SdGxAZJrwB+IemRiHgy\nf1xELAYWA7S1tQ37+3+1lOWk72QyM+tTZA1iA3B8bnl6WtePpLOAzwPnRcSu2vqI2JD+XgvcDZxS\nVEFrNQiPhTAz61NkQKwAZkmaKWkcsBDodzeSpFOA68nC4bnc+imSxqfXRwJnAPnO7VFV64NwDcLM\nrE9hTUwR0SXpcuA2oAwsiYiVkq4C2iNiGfA14FDgp+nuoaci4jxgNnC9pB6yELt6wN1Po6pSTk1M\nHgthZtar0D6IiFgOLB+w7src67MGOe7XwOuKLFterQbhTmozsz4eSU02khrcxGRmlueAIJuLCaDb\no6nNzHo5IMhmcwXodB+EmVkvBwRQKbmT2sxsIAcEUK7VINzEZGbWywFB30jqbndSm5n1ckDguZjM\nzOpxQNDXSe0+CDOzPg4IoNw7WZ9rEGZmNQ4IcnMxuQZhZtbLAYFHUpuZ1eOAwJ3UZmb1OCBwE5OZ\nWT0OCPqm+/Y4CDOzPg4IoFrySGozs4EcEPiBQWZm9Tgg6Jvu253UZmZ9HBD0jaR2H4SZWR8HBLnp\nvh0QZma9HBD4mdRmZvU4IIBSSZTkJiYzszwHRFIpl/zIUTOzHAdEUi2JLjcxmZn1ckAk5ZLcSW1m\nllNoQEiaL2m1pDWSFtXZ/ilJqyQ9LOlOSSfmtl0i6Yn055IiywnZjK5+HoSZWZ/CAkJSGbgWeBcw\nB7hI0pwBuz0ItEXE64Gbga+mY48Avgi8CZgHfFHSlKLKCtmMrh5JbWbWp8gaxDxgTUSsjYjdwFJg\nQX6HiLgrIranxXuB6en1O4HbI2JzRLwA3A7ML7CsVErupDYzyysyIKYB63PLHWndYC4Ffr4vx0q6\nTFK7pPaNGzeOqLCVstzEZGaWc0B0Uku6GGgDvrYvx0XE4ohoi4i21tbWEZWh4k5qM7N+igyIDcDx\nueXpaV0/ks4CPg+cFxG79uXY0VQtl3ybq5lZTpEBsQKYJWmmpHHAQmBZfgdJpwDXk4XDc7lNtwFn\nS5qSOqfPTusK405qM7P+KkW9cUR0Sbqc7Bd7GVgSESslXQW0R8QysialQ4GfSgJ4KiLOi4jNkv6K\nLGQAroqIzUWVFaBcKtHpJiYzs16FBQRARCwHlg9Yd2Xu9Vl7OHYJsKS40vVXLYlud1KbmfU6IDqp\nDwSVsnybq5lZjgMiqZTcSW1mlueASLJxEK5BmJnVOCCSrAbhgDAzq3FAJFWPpDYz68cBkZRLHgdh\nZpbngEiq5RKdrkGYmfVyQCSVkuh2DcLMrJcDIqmUPZLazCzPAZFU/ExqM7N+HBCJJ+szM+vPAZFk\nz6R2QJiZ1TggkuyBQW5iMjOrcUAklVI2WV+EaxFmZuCA6FUpZz+KbjczmZkBDohelbIA3A9hZpY4\nIJJqKftROCDMzDIOiKRcSjUIj4UwMwMcEL2qqYnJT5UzM8s4IBJ3UpuZ9eeASGpNTJ1uYjIzA4YY\nEJI+IekwZb4v6QFJZxdduP2p6ruYzMz6GWoN4r9ExIvA2cAU4IPA1YWVagxUSrUmJtcgzMxg6AGh\n9Pe7gR9GxMrcuobgTmozs/6GGhD3S/pXsoC4TdIkYK9ftSXNl7Ra0hpJi+psf2tqruqSdMGAbd2S\nHkp/lg2xnMNWro2DcECYmQFQGeJ+lwJzgbURsV3SEcCH93SApDJwLfAOoANYIWlZRKzK7fYU8CHg\nL+q8xY6ImDvE8o1YbSS1HztqZpYZag3ij4DVEbFF0sXAF4CtezlmHrAmItZGxG5gKbAgv0NErIuI\nhxlCbaRo1ZJvczUzyxtqQHwX2C7pDcCngSeBH+zlmGnA+txyR1o3VC2S2iXdK+n8ejtIuizt075x\n48Z9eOs/1FuD8G2uZmbA0AOiK7J5sBcA10TEtcCk4ooFwIkR0QZ8APiGpFcO3CEiFkdEW0S0tba2\njujDKr1TbbgGYWYGQw+IbZKuILu99Z8llYDqXo7ZAByfW56e1g1JRGxIf68F7gZOGeqxw1EbSe2H\nBpmZZYYaEBcCu8jGQzxD9sv+a3s5ZgUwS9JMSeOAhcCQ7kaSNEXS+PT6SOAMYNWejxoZ1yDMzPob\nUkCkUPgRMFnSucDOiNhjH0REdAGXA7cBjwE3RcRKSVdJOg9A0mmSOoD3AddLWpkOnw20S/oP4C7g\n6gF3P426atnTfZuZ5Q3pNldJ7yerMdxNNkDu25I+ExE37+m4iFgOLB+w7src6xVktZGBx/0aeN1Q\nyjZaPBeTmVl/Qx0H8XngtIh4DkBSK3AHsMeAOJj0zsXkJiYzM2DofRClWjgkm/bh2IOCp/s2M+tv\nqDWIf5F0G3BjWr6QAU1HB7taJ7VHUpuZZYYUEBHxGUnvJbubCGBxRNxaXLH2P9/FZGbW31BrEETE\nLcAtBZZlTNWamNxJbWaW2WNASNoG1PtKLSAi4rBCSjUGap3U7oMwM8vsMSAioujpNA4YtdtcPQ7C\nzCzTUHcijURtNlc3MZmZZRwQSakkSnIntZlZjQMip1IuuYnJzCxxQORUSqLLTUxmZoADop9KSa5B\nmJklDoicarnkTmozs8QBkVMpy+MgzMwSB0ROpVSi03cxmZkBDoh+KmX5kaNmZokDIie7i8k1CDMz\ncED0Uy2XXIMwM0scEDll1yDMzHo5IHIq5RKdvovJzAxwQPRTLYluNzGZmQEOiH7KJfk2VzOzxAGR\nUy2XPBeTmVnigMjJxkG4BmFmBgUHhKT5klZLWiNpUZ3tb5X0gKQuSRcM2HaJpCfSn0uKLGdNpVTy\nXUxmZklhASGpDFwLvAuYA1wkac6A3Z4CPgT8eMCxRwBfBN4EzAO+KGlKUWWtyWZzdROTmRkUW4OY\nB6yJiLURsRtYCizI7xAR6yLiYWDgb+V3ArdHxOaIeAG4HZhfYFmB1MTkGoSZGVBsQEwD1ueWO9K6\nUTtW0mWS2iW1b9y4cdgFramWS3S6BmFmBhzkndQRsTgi2iKirbW1dcTvVymJbtcgzMyAYgNiA3B8\nbnl6Wlf0scNWKcsjqc3MkiIDYgUwS9JMSeOAhcCyIR57G3C2pCmpc/rstK5Q2V1MbmIyM4MCAyIi\nuoDLyX6xPwbcFBErJV0l6TwASadJ6gDeB1wvaWU6djPwV2QhswK4Kq0rlDupzcz6VIp884hYDiwf\nsO7K3OsVZM1H9Y5dAiwpsnwDZdN9OyDMzOAg76QebWWPgzAz6+WAyKmmyfoiXIswM3NA5FTK2Y+j\n281MZmYOiLxySQDuhzAzwwHRT7XsgDAzq3FA5FRK2Y/DYyHMzBwQ/dRqEH6qnJmZA6Kfcsmd1GZm\nNQ6InEpvDcJNTGZmDogcd1KbmfVxQOS4k9rMrI8DIqficRBmZr0cEDm1kdSe0dXMzAHRT28ntSfs\nMzNzQORVS65BmJnVOCBy+uZicg3CzMwBkdN7m6trEGZmDoi83k5q1yDMzBwQeb23uboGYWbmgMir\neCS1mVkvB0RObSS152IyM3NA9ONOajOzPg6InNptrp7u28zMAdFPNd3F5JHUZmYFB4Sk+ZJWS1oj\naVGd7eMl/SRtv0/SjLR+hqQdkh5Kf64rspw1vovJzKxPpag3llQGrgXeAXQAKyQti4hVud0uBV6I\niFdJWgh8BbgwbXsyIuYWVb56auMg3EltZlZsDWIesCYi1kbEbmApsGDAPguAG9Lrm4G3S1KBZdqj\nivsgzMx6FRkQ04D1ueWOtK7uPhHRBWwFpqZtMyU9KOmXkt5S7wMkXSapXVL7xo0bR1xgj4MwM+tz\noHZSPw2cEBGnAJ8CfizpsIE7RcTiiGiLiLbW1tYRf2i1VKJcEtt3d434vczMDnZFBsQG4Pjc8vS0\nru4+kirAZGBTROyKiE0AEXE/8CTw6gLLCkCpJI6aNJ5ntu4q+qPMzA54RQbECmCWpJmSxgELgWUD\n9lkGXJJeXwD8IiJCUmvq5EbSK4BZwNoCy9rrmMktPPPijv3xUWZmB7TC7mKKiC5JlwO3AWVgSUSs\nlHQV0B4Ry4DvAz+UtAbYTBYiAG8FrpLUCfQAH42IzUWVNe+4yRN47OkX98dHmZkd0AoLCICIWA4s\nH7DuytzrncD76hx3C3BLkWUbzDGTW/jF488REYzhDVVmZmPuQO2kHjPHTm5hR2c3L+5wR7WZNTcH\nxADHTG4B4Gn3Q5hZk3NADHBsLSC27BzjkpiZjS0HxADHTp4AwNNbHRBm1twcEAO0ThpPSfDMVjcx\nmVlzc0AMUC2XaJ003jUIM2t6Dog6jpk8wQFhZk3PAVHHcZNbeNpNTGbW5BwQdRwzuYWnt+4kwrO6\nmlnzckDUcezkFrbv7mbbLg+WM7Pm5YCo45jara4eC2FmTcwBUcdxtcFy7ocwsybmgKijNt3GM76T\nycyamAOijqMmtSB5NLWZNTcHRB3jKiWOPHS8axBm1tQcEIM4bnILv3cfhJk1MQfEII6Z3OIahJk1\nNQfEII6dPMEBYWZNzQExiGMmt7BtVxfbdnaOdVHMzMaEA2IQx/pWVzNrcg6IQfjBQWbW7BwQg3AN\nwsyanQNiEEcdNh6AdZteHuOSmJmNjcpYF+BANb5S5o0nHM53f/kkJYlPnDWLatl5ambNo9DfeJLm\nS1otaY2kRXW2j5f0k7T9PkkzctuuSOtXS3pnkeUczA8vfRMXvHE619y1hvdddw/3PLmJlzwFuJk1\nCRX1UBxJZeD/Ae8AOoAVwEURsSq3z/8AXh8RH5W0EPhPEXGhpDnAjcA84DjgDuDVEdE92Oe1tbVF\ne3t7IefyTw//nit+9gjbdnYhwcwjD+GVrYdy1KTxHDWphSmHVGmplplQLTOuUqIsUSqBJJTeoyQx\nYVy2z/hKiZ6Angh6Bvz8SxLlkigJunqC3V09dHb3ANm6ktRvfbkkKiVRrZSIgO6eoCutnzCuTEu1\nTLkkenqC7gi6e4KenuyzB175iKAnoFISRxwyjqmHjmPiOFcyzRqZpPsjoq3etiL/988D1kTE2lSI\npcACYFVunwXAl9Lrm4FrJCmtXxoRu4DfSlqT3u+eAss7qHNffxxvftWRPPDUCzzS8SKPbNjKU5u2\n075uMy9sb+xxEuMqJSZUy7RUS4yvlCkpCz6gN/z+cKG+IexywKid40gN9QvYaH3ecMox3M8u4j0P\nNsP5gj0aP5uBnzv72MO45gNvHPH7DlRkQEwD1ueWO4A3DbZPRHRJ2gpMTevvHXDstIEfIOky4DKA\nE044YdQKXs/hE8fxttcczdtec3S/9bu6utm2s4sdu7vZ2dnNrq6e7Jv8gNpBT0+wo7ObHbuzfbKa\nAoCo/XuJyC58d/omXy2JarlEtZK1BPZEEBGUSyWqZTGunNVEOrt72N3dg4BqudRbY9jR2c323d30\nRORqJn01lFLuH2oQvTWeru5g8/bdbH55Ny9s383O3d3s7OxhV1c3PVHbv89Q/pMcMA9vDfaeVKNd\n2P39eYOpV46RfnYR77mPgkBj+fVjsJ9B0T+b3PufOHXiKL5xn4O6/SAiFgOLIWtiGosyjK+UGX9o\neSw+2sysUEV2Um8Ajs8tT0/r6u4jqQJMBjYN8VgzMytQkQGxApglaaakccBCYNmAfZYBl6TXFwC/\niKy9YhmwMN3lNBOYBfymwLKamdkAhTUxpT6Fy4HbgDKwJCJWSroKaI+IZcD3gR+mTujNZCFC2u8m\nsg7tLuBje7qDyczMRl9ht7nub0Xe5mpm1qj2dJurhwabmVldDggzM6vLAWFmZnU5IMzMrK6G6aSW\ntBH43Qje4kjg+VEqzsGiGc8ZmvO8m/GcoTnPe1/P+cSIaK23oWECYqQktQ/Wk9+omvGcoTnPuxnP\nGZrzvEfznN3EZGZmdTkgzMysLgdEn8VjXYAx0IznDM153s14ztCc5z1q5+w+CDMzq8s1CDMzq8sB\nYWZmdTV9QEiaL2m1pDWSFo11eYoi6XhJd0laJWmlpE+k9UdIul3SE+nvKWNd1tEmqSzpQUn/lJZn\nSrovXfOfpOnoG4qkwyXdLOlxSY9J+qNGv9aS/jz9235U0o2SWhrxWktaIuk5SY/m1tW9tsp8K53/\nw5L26bmkTR0QksrAtcC7gDnARZLmjG2pCtMFfDoi5gCnAx9L57oIuDMiZgF3puVG8wngsdzyV4C/\niYhXAS8Al45JqYr1TeBfIuI1wBvIzr9hr7WkacDHgbaIeC3ZIwYW0pjX+u+A+QPWDXZt30X2PJ1Z\nZI9n/u6+fFBTBwQwD1gTEWsjYjewFFgwxmUqREQ8HREPpNfbyH5hTCM73xvSbjcA549NCYshaTpw\nDvC3aVnA24Cb0y6NeM6TgbeSPW+FiNgdEVto8GtN9nybCenplBOBp2nAax0R/0b2/Jy8wa7tAuAH\nkbkXOFzSsUP9rGYPiGnA+txyR1rX0CTNAE4B7gOOjoin06ZngKPHqFhF+QbwP4GetDwV2BIRXWm5\nEa/5TGAj8H9S09rfSjqEBr7WEbEB+GvgKbJg2ArcT+Nf65rBru2Ifsc1e0A0HUmHArcAn4yIF/Pb\n0uNeG+a+Z0nnAs9FxP1jXZb9rAK8EfhuRJwCvMyA5qQGvNZTyL4tzwSOAw7hD5thmsJoXttmD4gN\nwPG55elpXUOSVCULhx9FxM/S6mdrVc7093NjVb4CnAGcJ2kdWfPh28ja5g9PzRDQmNe8A+iIiPvS\n8s1kgdHI1/os4LcRsTEiOoGfkV3/Rr/WNYNd2xH9jmv2gFgBzEp3Oowj69RaNsZlKkRqe/8+8FhE\nfD23aRlwSXp9CfB/93fZihIRV0TE9IiYQXZtfxERfwbcBVyQdmuocwaIiGeA9ZJOSqveTvZ894a9\n1mRNS6dLmpj+rdfOuaGvdc5g13YZ8J/T3UynA1tzTVF71fQjqSW9m6ydugwsiYgvj3GRCiHpzcC/\nA4/Q1x7/ObJ+iJuAE8imS39/RAzsADvoSToT+IuIOFfSK8hqFEcADwIXR8SusSzfaJM0l6xjfhyw\nFvgw2RfChr3Wkv4SuJDsjr0Hgf9K1t7eUNda0o3AmWTTej8LfBH4B+pc2xSW15A1t20HPhwR7UP+\nrGYPCDMzq6/Zm5jMzGwQDggzM6vLAWFmZnU5IMzMrC4HhJmZ1eWAMDsASDqzNtus2YHCAWFmZnU5\nIMz2gaSLJf1G0kOSrk/PmnhJ0t+kZxHcKak17TtX0r1pHv5bc3P0v0rSHZL+Q9IDkl6Z3v7Q3DMc\nfpQGOZmNGQeE2RBJmk02UveMiJgLdAN/RjYxXHtEnAz8kmxkK8APgM9GxOvJRrDX1v8IuDYi3gD8\nMdnso5DNsPtJsmeTvIJsLiGzMVPZ+y5mlrwdOBVYkb7cTyCbFK0H+Ena5++Bn6VnMhweEb9M628A\nfippEjAtIm4FiIidAOn9fhMRHWn5IWAG8KviT8usPgeE2dAJuCEirui3UvpfA/Yb7vw1+TmCuvH/\nTxtjbmIyG7o7gQskHQW9zwE+kez/UW3G0A8Av4qIrcALkt6S1n8Q+GV6ml+HpPPTe4yXNHG/noXZ\nEPkbitkQRcQqSV8A/lVSCegEPkb2QJ55adtzZP0UkE27fF0KgNqMqpCFxfWSrkrv8b79eBpmQ+bZ\nXM1GSNJLEXHoWJfDbLS5icnMzOpyDcLMzOpyDcLMzOpyQJiZWV0OCDMzq8sBYWZmdTkgzMysrv8P\nu5wDc3UGq4sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA5WOYpocUZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The algorithm uses data of the previous 25 time-steps to forecast the following 10th minute into the future. Therefore,  \n",
        "# the first prediction of every day can only be excecuted after 25 minutes of the begining of the day, and will refer  \n",
        "# to the prediction of the minute 35. Also the data is first stationarized by apply the diff() function with then subtracts\n",
        "# the following row from the previous. \n",
        "\n",
        "# Since every day consists of 1440 minutes the algorithm is only able to predict the last 1404 minutes of the day.\n",
        "\n",
        "#Create a Dataframe to hold the true predicted values for each day.\n",
        "def createPredictionsData(days):  \n",
        "  predictionsData = DayTrade.copy()\n",
        "  predictionsData = predictionsData.loc[:,['Weighted_Price','date']]\n",
        "  predictionsData = predictionsData[predictionsData['date'].isin(days)]# Filter only the testing days\n",
        "  predictionsData = predictionsData.groupby('date').apply(lambda group: group.iloc[35:])# For each day filter the last 1405 minutes (1440 - 1405 = 35)\n",
        "  predictionsData = predictionsData.drop(columns='date')\n",
        "  predictionsData = predictionsData.reset_index()\n",
        "\n",
        "  return(predictionsData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efSaKaIQcUZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(modelFilename, days):\n",
        "\n",
        "    predictionsData = createPredictionsData(days)\n",
        "    \n",
        "    column_name = modelFilename.split('.')[0]\n",
        "    #Step 1 - Create a column to hold predictions\n",
        "    predictionsData['Prediction_Weighted_Price'] = np.nan #[3]\n",
        "    \n",
        "    \n",
        "    #Step 2 - load model for prediction   \n",
        "    loaded_model = tf.keras.models.load_model(modelFilename)\n",
        "    \n",
        "    for day in days:\n",
        "        #Step 3 - Filter Input data and Target with the selected date\n",
        "        day_test_data = DayTrade_clean[DayTrade_clean['date'].values==day]\n",
        "        day_label_data = target_data_clean[target_data_clean['date'].values==day]\n",
        "        \n",
        "        batch_size = len(day_test_data) - sequence_length\n",
        "         \n",
        "        \n",
        "        #Step 3 - Drop date columns from day test data and day label data\n",
        "        day_test_data = day_test_data.drop(columns=['date'])\n",
        "        day_label_data = day_label_data.drop(columns=['date']).shift(1)\n",
        "\n",
        "        #Step 4 - Convert day data into numpy array\n",
        "        day_test_data = np.array(day_test_data)\n",
        "        day_label_data = np.array(day_label_data)\n",
        "        \n",
        "        #Step 5 - Scale data for Neural Network (all features except Weighted Price)\n",
        "        day_test_data = x_scaler.transform(day_test_data)\n",
        "        day_label_data = y_scaler.transform(day_label_data)\n",
        "        \n",
        "               \n",
        "        #Step 6 - Generate batches of sequence of data\n",
        "        generator = TimeseriesGenerator(day_test_data, day_label_data, length=sequence_length, batch_size=batch_size)\n",
        "\n",
        "        x_batch = np.zeros(shape=(batch_size ,sequence_length, num_x_signal))\n",
        "        y_batch = np.zeros(shape=(batch_size ,sequence_length, num_y_signal))\n",
        "\n",
        "        x_batch, y_batch = generator[0]\n",
        "\n",
        "        #Step 9 - Generate the prediction for that day   \n",
        "        ypred = loaded_model.predict(x_batch)\n",
        "        ypred_rescaled = y_scaler.inverse_transform(ypred)\n",
        "        \n",
        "        index_list = []\n",
        "        index_list = predictionsData.index[predictionsData['date']==day].tolist()\n",
        "\n",
        "        predictionsData.iloc[index_list[0]:index_list[0]+len(index_list),3] = ypred_rescaled\n",
        "\n",
        "    \n",
        "    return(predictionsData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjswtiLzf7Bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_file = 'DayTrade with DailySummary Model(seed 10).19-0.0001.h5'\n",
        "modelPath = '/content/drive/My Drive/Capstone/FinalModels/Step4-DayTrade_DailySummaryInputs/Seed 10'\n",
        "modelfilePath = modelPath + '/' + model_file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KN1qC_tcUZx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "9c0a3141-e17b-45a9-dbd1-464e6e076113"
      },
      "source": [
        "predictionsData = predict(modelfilePath, testing_days)\n",
        "predictionsData"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>Time</th>\n",
              "      <th>Weighted_Price</th>\n",
              "      <th>Prediction_Weighted_Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-02-19</td>\n",
              "      <td>2019-02-19 00:35:00</td>\n",
              "      <td>3901.527342</td>\n",
              "      <td>3442.442139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-02-19</td>\n",
              "      <td>2019-02-19 00:36:00</td>\n",
              "      <td>3910.106934</td>\n",
              "      <td>3447.895752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-02-19</td>\n",
              "      <td>2019-02-19 00:37:00</td>\n",
              "      <td>3913.037224</td>\n",
              "      <td>3455.857666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-02-19</td>\n",
              "      <td>2019-02-19 00:38:00</td>\n",
              "      <td>3933.854943</td>\n",
              "      <td>3457.452148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-02-19</td>\n",
              "      <td>2019-02-19 00:39:00</td>\n",
              "      <td>3935.166985</td>\n",
              "      <td>3477.653076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244465</th>\n",
              "      <td>2019-08-11</td>\n",
              "      <td>2019-08-11 23:55:00</td>\n",
              "      <td>11550.565971</td>\n",
              "      <td>11963.412109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244466</th>\n",
              "      <td>2019-08-11</td>\n",
              "      <td>2019-08-11 23:56:00</td>\n",
              "      <td>11552.336234</td>\n",
              "      <td>11944.670898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244467</th>\n",
              "      <td>2019-08-11</td>\n",
              "      <td>2019-08-11 23:57:00</td>\n",
              "      <td>11555.520505</td>\n",
              "      <td>11903.083984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244468</th>\n",
              "      <td>2019-08-11</td>\n",
              "      <td>2019-08-11 23:58:00</td>\n",
              "      <td>11559.252199</td>\n",
              "      <td>11857.011719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244469</th>\n",
              "      <td>2019-08-11</td>\n",
              "      <td>2019-08-11 23:59:00</td>\n",
              "      <td>11575.638889</td>\n",
              "      <td>11822.894531</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>244470 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              date  ... Prediction_Weighted_Price\n",
              "0       2019-02-19  ...               3442.442139\n",
              "1       2019-02-19  ...               3447.895752\n",
              "2       2019-02-19  ...               3455.857666\n",
              "3       2019-02-19  ...               3457.452148\n",
              "4       2019-02-19  ...               3477.653076\n",
              "...            ...  ...                       ...\n",
              "244465  2019-08-11  ...              11963.412109\n",
              "244466  2019-08-11  ...              11944.670898\n",
              "244467  2019-08-11  ...              11903.083984\n",
              "244468  2019-08-11  ...              11857.011719\n",
              "244469  2019-08-11  ...              11822.894531\n",
              "\n",
              "[244470 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlBHNrLAcUZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save Dataframe with prediction as csv file\n",
        "prediction_file = '/content/drive/My Drive/Capstone/FinalModels/Step4-DayTrade_DailySummaryInputs/Seed 10/'+'predictions_' +  model_file.split('.')[0] + '.csv'\n",
        "prediction_filePath = '/content/' + prediction_file\n",
        "predictionsData.to_csv(prediction_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zntWdZ5QNDmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "mse_Weighted_Price = mean_squared_error(predictionsData.iloc[:,2],predictionsData.iloc[:,3])\n",
        "mae_Weighted_Price = mean_absolute_error(predictionsData.iloc[:,2],predictionsData.iloc[:,3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2yk1deqWScj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c12c1703-fda6-41fc-fdef-f10d66a0e9e9"
      },
      "source": [
        "print(mse_Weighted_Price,mae_Weighted_Price)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "97924.4278082401 242.01179045603834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eshRDEItACAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}