{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "DayTradeSinglePrediction_FinalModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmaciver/Ryerson_Capstone/blob/master/FinalModel/Step2-DayTrade/DayTradeSinglePrediction_FinalModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucrs5sJ-mh5G",
        "colab_type": "code",
        "outputId": "b94f9197-0ebd-4c39-be7c-8c5bdab1d54a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QB9qARYlsLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, QuantileTransformer\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms9FlgRKlsLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Input, Dense, GRU, Embedding, LSTM, TimeDistributed, Lambda, Dropout\n",
        "from tensorflow.python.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras import losses\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import random as rand\n",
        "from random import randint\n",
        "from numpy.random import seed\n",
        "seed(10)\n",
        "from tensorflow.compat.v1 import set_random_seed\n",
        "set_random_seed(2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLY_ntS2lsLp",
        "colab_type": "code",
        "outputId": "69365d11-6e3f-4b5e-a6fa-d56542ee8a26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "file_path = \"/content/drive/My Drive/Capstone/Data Exploration/Day_trade_data.csv\"\n",
        "DayTrade = pd.read_csv(file_path, index_col='Time')\n",
        "DayTrade = DayTrade.drop([DayTrade.columns[0]] ,  axis='columns')\n",
        "DayTrade.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume_.BTC.</th>\n",
              "      <th>Volume_.Currency.</th>\n",
              "      <th>Weighted_Price</th>\n",
              "      <th>date</th>\n",
              "      <th>Open_RoC</th>\n",
              "      <th>High_RoC</th>\n",
              "      <th>Low_RoC</th>\n",
              "      <th>Close_RoC</th>\n",
              "      <th>Weighted_Price_RoC</th>\n",
              "      <th>RSI</th>\n",
              "      <th>MACD_index</th>\n",
              "      <th>slow_stoch</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-04-03 00:00:00</th>\n",
              "      <td>116.00</td>\n",
              "      <td>116.00</td>\n",
              "      <td>116.00</td>\n",
              "      <td>116.00</td>\n",
              "      <td>31.713233</td>\n",
              "      <td>3678.735005</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>2013-04-03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>-0.36038</td>\n",
              "      <td>0.084906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 00:01:00</th>\n",
              "      <td>116.00</td>\n",
              "      <td>116.00</td>\n",
              "      <td>116.00</td>\n",
              "      <td>116.00</td>\n",
              "      <td>31.713233</td>\n",
              "      <td>3678.735005</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>2013-04-03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>-0.36038</td>\n",
              "      <td>0.084906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 00:02:00</th>\n",
              "      <td>116.00</td>\n",
              "      <td>116.58</td>\n",
              "      <td>116.00</td>\n",
              "      <td>116.58</td>\n",
              "      <td>2.050985</td>\n",
              "      <td>238.357034</td>\n",
              "      <td>116.215883</td>\n",
              "      <td>2013-04-03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004988</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004988</td>\n",
              "      <td>0.001859</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>-0.36038</td>\n",
              "      <td>0.084906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 00:03:00</th>\n",
              "      <td>116.98</td>\n",
              "      <td>117.00</td>\n",
              "      <td>116.98</td>\n",
              "      <td>117.00</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>2690.890000</td>\n",
              "      <td>116.995217</td>\n",
              "      <td>2013-04-03</td>\n",
              "      <td>0.008413</td>\n",
              "      <td>0.003596</td>\n",
              "      <td>0.008413</td>\n",
              "      <td>0.003596</td>\n",
              "      <td>0.006684</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>-0.36038</td>\n",
              "      <td>0.084906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 00:04:00</th>\n",
              "      <td>117.00</td>\n",
              "      <td>117.00</td>\n",
              "      <td>117.00</td>\n",
              "      <td>117.00</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>5850.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>2013-04-03</td>\n",
              "      <td>0.000171</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000171</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>-0.36038</td>\n",
              "      <td>0.084906</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Open    High     Low  ...        RSI  MACD_index  slow_stoch\n",
              "Time                                         ...                                   \n",
              "2013-04-03 00:00:00  116.00  116.00  116.00  ...  33.333333    -0.36038    0.084906\n",
              "2013-04-03 00:01:00  116.00  116.00  116.00  ...  33.333333    -0.36038    0.084906\n",
              "2013-04-03 00:02:00  116.00  116.58  116.00  ...  33.333333    -0.36038    0.084906\n",
              "2013-04-03 00:03:00  116.98  117.00  116.98  ...  33.333333    -0.36038    0.084906\n",
              "2013-04-03 00:04:00  117.00  117.00  117.00  ...  33.333333    -0.36038    0.084906\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjHXkvf-lsLx",
        "colab_type": "text"
      },
      "source": [
        "Dropping Volume Currency as discussed in the Feature Selection phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIlci9pwlsLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DayTrade = DayTrade.drop(columns='Volume_.Currency.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xat-lJpslsL8",
        "colab_type": "code",
        "outputId": "c9e9427f-a22c-43eb-f626-279b017b7b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "#We need create a target data, which is basically a copy of the data that will be later shifted\n",
        "target_data = DayTrade.copy()\n",
        "target_data = target_data.iloc[:,5:7]\n",
        "target_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weighted_Price</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-04-03 00:00:00</th>\n",
              "      <td>116.000000</td>\n",
              "      <td>2013-04-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 00:01:00</th>\n",
              "      <td>116.000000</td>\n",
              "      <td>2013-04-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 00:02:00</th>\n",
              "      <td>116.215883</td>\n",
              "      <td>2013-04-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 00:03:00</th>\n",
              "      <td>116.995217</td>\n",
              "      <td>2013-04-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 00:04:00</th>\n",
              "      <td>117.000000</td>\n",
              "      <td>2013-04-03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Weighted_Price        date\n",
              "Time                                           \n",
              "2013-04-03 00:00:00      116.000000  2013-04-03\n",
              "2013-04-03 00:01:00      116.000000  2013-04-03\n",
              "2013-04-03 00:02:00      116.215883  2013-04-03\n",
              "2013-04-03 00:03:00      116.995217  2013-04-03\n",
              "2013-04-03 00:04:00      117.000000  2013-04-03"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRCpL0F_lsMF",
        "colab_type": "text"
      },
      "source": [
        "The objective of the model is to predict 10 minutes ahead of the current timestep. The Day Trade data contains the minute to minute data for a total of 1735 days. The analysis must be limited within each day."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNwvPFu2lsMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict 10 minutes in the future, although the predictions must be wrapped around each day\n",
        "shift_steps = 10\n",
        "\n",
        "# Now that the target_data was created we need to shift the data so that the target values of 24 hours later aling with our\n",
        "# input data\n",
        "\n",
        "target_data = target_data.groupby('date').shift(-shift_steps)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pwr1eLOglsMQ",
        "colab_type": "text"
      },
      "source": [
        "Here we double check that because we shifted the target values now we have NaN values at the end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkzvDkCtlsMS",
        "colab_type": "code",
        "outputId": "4dbcf524-4da9-45ac-d278-d569ef3cca44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        }
      },
      "source": [
        "target_data.iloc[1420:1450]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weighted_Price</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:40:00</th>\n",
              "      <td>129.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:41:00</th>\n",
              "      <td>129.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:42:00</th>\n",
              "      <td>129.899861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:43:00</th>\n",
              "      <td>129.892440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:44:00</th>\n",
              "      <td>130.049341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:45:00</th>\n",
              "      <td>131.371316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:46:00</th>\n",
              "      <td>132.534018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:47:00</th>\n",
              "      <td>132.912123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:48:00</th>\n",
              "      <td>132.819273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:49:00</th>\n",
              "      <td>133.091659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:50:00</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:51:00</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:52:00</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:53:00</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:54:00</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:55:00</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:56:00</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:57:00</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:58:00</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-03 23:59:00</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-08 00:00:00</th>\n",
              "      <td>164.628270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-08 00:01:00</th>\n",
              "      <td>164.971825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-08 00:02:00</th>\n",
              "      <td>164.990000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-08 00:03:00</th>\n",
              "      <td>164.986254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-08 00:04:00</th>\n",
              "      <td>164.998242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-08 00:05:00</th>\n",
              "      <td>164.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-08 00:06:00</th>\n",
              "      <td>164.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-08 00:07:00</th>\n",
              "      <td>164.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-08 00:08:00</th>\n",
              "      <td>164.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-08 00:09:00</th>\n",
              "      <td>164.960000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Weighted_Price\n",
              "Time                               \n",
              "2013-04-03 23:40:00      129.900000\n",
              "2013-04-03 23:41:00      129.900000\n",
              "2013-04-03 23:42:00      129.899861\n",
              "2013-04-03 23:43:00      129.892440\n",
              "2013-04-03 23:44:00      130.049341\n",
              "2013-04-03 23:45:00      131.371316\n",
              "2013-04-03 23:46:00      132.534018\n",
              "2013-04-03 23:47:00      132.912123\n",
              "2013-04-03 23:48:00      132.819273\n",
              "2013-04-03 23:49:00      133.091659\n",
              "2013-04-03 23:50:00             NaN\n",
              "2013-04-03 23:51:00             NaN\n",
              "2013-04-03 23:52:00             NaN\n",
              "2013-04-03 23:53:00             NaN\n",
              "2013-04-03 23:54:00             NaN\n",
              "2013-04-03 23:55:00             NaN\n",
              "2013-04-03 23:56:00             NaN\n",
              "2013-04-03 23:57:00             NaN\n",
              "2013-04-03 23:58:00             NaN\n",
              "2013-04-03 23:59:00             NaN\n",
              "2013-04-08 00:00:00      164.628270\n",
              "2013-04-08 00:01:00      164.971825\n",
              "2013-04-08 00:02:00      164.990000\n",
              "2013-04-08 00:03:00      164.986254\n",
              "2013-04-08 00:04:00      164.998242\n",
              "2013-04-08 00:05:00      164.960000\n",
              "2013-04-08 00:06:00      164.960000\n",
              "2013-04-08 00:07:00      164.960000\n",
              "2013-04-08 00:08:00      164.960000\n",
              "2013-04-08 00:09:00      164.960000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1suUnhXlsMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we need to remove the rows with NaN values for the target data thus needing to exclude also the \n",
        "# 10 lines per day of the DayTrade data\n",
        "\n",
        "DayTrade['target'] = target_data['Weighted_Price']\n",
        "\n",
        "target_data['date'] = DayTrade['date']\n",
        "\n",
        "DayTrade_clean = DayTrade.dropna()\n",
        "target_data_clean = target_data.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OObMTitlsMh",
        "colab_type": "code",
        "outputId": "e1d879ba-7da6-41b8-d6df-fab144dfab38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "DayTrade_clean.shape, target_data_clean.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2481050, 16), (2481050, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "552T9UtMlsMp",
        "colab_type": "text"
      },
      "source": [
        "Number of rows for both data are correct since initially the data consisted of 1735 days of 1440 minutes (total of 2.481.050 rows) and now each day had the last 10 minutes so the total amount of rows must be 1735 days of 1430 minutes (total of 2.481.050)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgUi4ibklsMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the target column was only added to the DayTrade data in order to drop the correct rows.\n",
        "#Removing column 'target' from the DayTrade data\n",
        "\n",
        "DayTrade = DayTrade.drop(columns='target')\n",
        "DayTrade_clean = DayTrade_clean.drop(columns='target')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jmoz-W2lsMy",
        "colab_type": "text"
      },
      "source": [
        "In order to compare results with other models a 90% split is going to be made"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT9psvi3lsM0",
        "colab_type": "code",
        "outputId": "114c6813-2ca6-4382-c251-8526feb68ca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "days_in_data = list(dict.fromkeys(DayTrade_clean[\"date\"].values))\n",
        "\n",
        "split = 0.9\n",
        "\n",
        "training_days = days_in_data[:int(split*len(days_in_data))]\n",
        "testing_days = days_in_data[int(split*len(days_in_data)):]\n",
        "\n",
        "print(len(training_days),len(testing_days))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1561 174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIWJr82rlsM7",
        "colab_type": "text"
      },
      "source": [
        "Data will need to be normalized for predictions. A scaler will be fitted for the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZsTpj5PlsOt",
        "colab_type": "code",
        "outputId": "a71fa785-2bae-4d26-800d-3ffb91748ff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Step 1 - Convert day data into numpy array\n",
        "train_data = np.array(DayTrade_clean.loc[DayTrade_clean.date.isin(training_days),:].drop(columns='date'))\n",
        "label_data = np.array(target_data_clean.loc[target_data_clean.date.isin(training_days),:].drop(columns='date')).reshape(-1,1)\n",
        "\n",
        "#Step 2 - Scale data for Neural Network\n",
        "x_scaler = MinMaxScaler()\n",
        "x_scaler.fit(train_data)\n",
        "y_scaler = MinMaxScaler()\n",
        "y_scaler.fit(label_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler(copy=True, feature_range=(0, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9B6Pgpg6LDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_reshape(sequence_length, X_train_scale, Y_train_scale, num_x_signal, num_y_signal):\n",
        "    \"\"\"\n",
        "    Generator function for creating random batches of training-data.\n",
        "    \"\"\"\n",
        "    batch_size = X_train_scale.shape[1] // sequence_length\n",
        "    # Allocate a new array for the batch of input-signals.\n",
        "    x_shape = (batch_size, sequence_length, num_x_signal)\n",
        "    x_batch = np.zeros(shape=x_shape, dtype=np.float16)\n",
        "    \n",
        " \n",
        "    # Allocate a new array for the batch of output-signals.\n",
        "    y_shape = (batch_size, num_y_signal)\n",
        "    y_batch = np.zeros(shape=y_shape, dtype=np.float16)\n",
        "\n",
        "    #print(x_batch.shape, y_batch.shape, X_train_scale.shape, Y_train_scale.shape) #debugging\n",
        "    # Create Sequence for sliding window\n",
        "    seq = []\n",
        "    for i in range(batch_size):\n",
        "        seq.append(i*sequence_length)\n",
        "    \n",
        "    # Fill the batch with sequences of data.\n",
        "    for i in range(0,len(seq)-1):\n",
        "\n",
        "        # Copy the sequences of data starting at this index.\n",
        "        x_batch[i] = X_train_scale[0][seq[i]:seq[i]+sequence_length][:]\n",
        "        y_batch[i] = Y_train_scale[0][seq[i]+sequence_length-1][:]\n",
        "        #print(\"iteration: \",i,\"-OK\") #debugging\n",
        "\n",
        "    #print(x_batch.shape,y_batch.shape) #debbuging\n",
        "    return (x_batch, y_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gOZQQK9lsNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_generator(batch_size, sequence_length, num_x_signal, num_y_signal, train_data, label_data, training_days):\n",
        "    \n",
        "    # Create a Batch function for training data using sliding window technique\n",
        "    # Step 1 - Select a training day\n",
        "\n",
        "    day = rand.choice(training_days)\n",
        "\n",
        "    #Step 2 - Filter Input data and Target with the selected date\n",
        "    day_train_data = train_data[train_data['date'].values==day]\n",
        "    day_label_data = label_data[label_data['date'].values==day]\n",
        "\n",
        "    #Step 3 - Drop date columns from day train data and day label data\n",
        "    day_train_data = day_train_data.drop(columns='date')\n",
        "    day_label_data = day_label_data.drop(columns='date')\n",
        "\n",
        "    #Step 4 - Convert day data into numpy array\n",
        "    day_train_data = np.array(day_train_data)\n",
        "    day_label_data = np.array(day_label_data).reshape(-1,1)\n",
        "\n",
        "    #Step 5 - Scale data for Neural Network\n",
        "    day_train_data = x_scaler.transform(day_train_data)\n",
        "    day_label_data = y_scaler.transform(day_label_data)\n",
        "\n",
        "    #Step 6 - Reshape data to fit keras requirement to have a (x,y,z) shape\n",
        "    day_train_data = day_train_data.reshape(1,day_train_data.shape[0],day_train_data.shape[1])\n",
        "    day_label_data = day_label_data.reshape(1,day_label_data.shape[0],day_label_data.shape[1])\n",
        "    \n",
        "     #Step 7 - Reshape data into Batches\n",
        "    day_train_data_reshape , day_label_data_reshape =  batch_reshape(sequence_length, day_train_data, day_label_data, num_x_signal, num_y_signal)\n",
        "    \n",
        "    # print(day_train_data_reshape.shape , day_train_data_reshape.shape)#debugging\n",
        "   \n",
        "    #Step 8 - Apply the \"jumping\" slidding window technique to the reshaped date\n",
        "    # Infinite loop.\n",
        "    while True:\n",
        "        # Allocate a new array for the batch of input-signals.\n",
        "        x_shape = (batch_size, sequence_length, num_x_signal)\n",
        "        x_batch = np.zeros(shape=x_shape, dtype=np.float16)\n",
        "\n",
        "        # Allocate a new array for the batch of output-signals.\n",
        "        y_shape = (batch_size, num_y_signal)\n",
        "        y_batch = np.zeros(shape=y_shape, dtype=np.float16)\n",
        "\n",
        "        # Fill the batch with random continuous sequences of data.\n",
        "\n",
        "        # Get a random start-index.\n",
        "        # This points somewhere into the training-data.\n",
        "        idx = np.random.randint(day_train_data_reshape.shape[0] - batch_size)\n",
        "\n",
        "        # Copy the sequences of data starting at this index.\n",
        "        x_batch = day_train_data_reshape[idx:idx+batch_size]\n",
        "        y_batch = day_label_data_reshape[idx:idx+batch_size]\n",
        "\n",
        "\n",
        "        yield (x_batch, y_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjsNJ6OVlsNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_x_signal = 14 # number of input features\n",
        "num_y_signal = 1 # number of label classes\n",
        "\n",
        "batch_size = 50 # tunning parameter\n",
        "sequence_length = 25 #Amount of time-steps to look back for the 10 minute prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyewDvW6lsNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = batch_generator(batch_size,sequence_length, num_x_signal, num_y_signal, DayTrade_clean, target_data_clean,training_days)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCbJykW9lsNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_batch, y_batch = next(generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRGV8k-ElsNi",
        "colab_type": "code",
        "outputId": "34f8d9bb-f5ae-43d0-ac2a-4fbdb5402245",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(x_batch.shape)\n",
        "print(y_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 25, 14)\n",
            "(50, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a97sQHTwlsNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_validation(sequence_length, num_x_signal, num_y_signal, test_data, label_test_data, testing_days):\n",
        "    \n",
        "    # Create a Batch function for validation data using sliding window technique\n",
        "    # Step 1 - Select a testing day\n",
        "\n",
        "    day = rand.choice(testing_days)\n",
        "\n",
        "    #Step 2 - Filter Input data and Target with the selected date\n",
        "    day_test_data = test_data[test_data['date'].values==day]\n",
        "    day_label_data = label_test_data[label_test_data['date'].values==day]\n",
        "\n",
        "    #Step 3 - Drop date columns from day test data and day label data\n",
        "    day_test_data = day_test_data.drop(columns='date')\n",
        "    day_label_data = day_label_data.drop(columns='date')\n",
        "\n",
        "    #Step 4 - Convert day data into numpy array\n",
        "    day_test_data = np.array(day_test_data)\n",
        "    day_label_data = np.array(day_label_data).reshape(-1,1)\n",
        "\n",
        "    #Step 5 - Scale data for Neural Network\n",
        "    day_test_data = x_scaler.transform(day_test_data)\n",
        "    day_label_data = y_scaler.transform(day_label_data)\n",
        "\n",
        "    #Step 6 - Reshape data to fit keras requirement to have a (x,y,z) shape\n",
        "    day_test_data = day_test_data.reshape(1,day_test_data.shape[0],day_test_data.shape[1])\n",
        "    day_label_data = day_label_data.reshape(1,day_label_data.shape[0],day_label_data.shape[1])\n",
        "    \n",
        "    #print(day_test_data.shape , day_label_data.shape)#debugging\n",
        "    \n",
        "    #Step 7 - Reshape data into Batches using slidding window   \n",
        "    batch_val_size = day_test_data.shape[1] - sequence_length\n",
        "    \n",
        "    x_val_shape = (batch_val_size, sequence_length, num_x_signal)\n",
        "    x_batch = np.zeros(shape=x_val_shape, dtype=np.float16)\n",
        "        \n",
        "    y_val_shape = (batch_val_size, num_y_signal)\n",
        "    y_batch = np.zeros(shape=y_val_shape, dtype=np.float16)\n",
        "    \n",
        "    #print(x_batch.shape, y_batch.shape) # debugging\n",
        "    for i in range(batch_val_size):\n",
        "\n",
        "        # Copy the sequences of data starting at this index.\n",
        "        x_batch[i] = day_test_data[0][i:i+sequence_length][:]\n",
        "        y_batch[i] = day_label_data[0][i+sequence_length-1][:]\n",
        "\n",
        "    \n",
        "    return (x_batch, y_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHB0sxjvlsNu",
        "colab_type": "code",
        "outputId": "47abe0c2-fc59-4658-d22a-779ab5d39844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_val, Y_val = batch_validation(sequence_length,num_x_signal, num_y_signal, DayTrade_clean, target_data_clean, testing_days)\n",
        "print(X_val.shape, Y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1405, 25, 14) (1405, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JijIrUClsN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_data = (X_val, Y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxrLHSOZlsN8",
        "colab_type": "text"
      },
      "source": [
        "## Create Recurrent Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccoKnJPolsN-",
        "colab_type": "code",
        "outputId": "83789b94-8692-4cd8-bb1d-e154b0448dde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=200,\n",
        "              return_sequences=True,\n",
        "              input_shape=(None,num_x_signal,)))\n",
        "model.add(LSTM(units=150, return_sequences=False))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(num_y_signal,activation='linear'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_14 (LSTM)               (None, None, 200)         172000    \n",
            "_________________________________________________________________\n",
            "lstm_15 (LSTM)               (None, 150)               210600    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 150)               600       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 151       \n",
            "=================================================================\n",
            "Total params: 383,351\n",
            "Trainable params: 383,051\n",
            "Non-trainable params: 300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3GwP4Z4lsOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(lr=1e-3)\n",
        "\n",
        "model.compile(loss=tf.keras.losses.logcosh, optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U37PF2alsOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_file = \"DayTrade Model(seed 10).{epoch:02d}-{val_loss:.7f}.h5\"\n",
        "\n",
        "mc = ModelCheckpoint('/content/drive/My Drive/Capstone/FinalModels/Step2-DayTrade/Seed 10/'+model_file, monitor=\"val_loss\", mode=\"min\", save_best_only=True)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.8,\n",
        "                              patience=4, min_lr=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-Ohrxs6lsOP",
        "colab_type": "code",
        "outputId": "4b46c24f-4ecc-41cd-8cad-fad163213410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "history = model.fit_generator(generator=generator,\n",
        "                    epochs=100,\n",
        "                    steps_per_epoch=50,\n",
        "                    validation_data=validation_data,\n",
        "                    callbacks=[ mc, reduce_lr])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50/50 [==============================] - 9s 182ms/step - loss: 0.2825 - val_loss: 0.0083 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 8s 167ms/step - loss: 0.0372 - val_loss: 0.0085 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 8s 167ms/step - loss: 0.0048 - val_loss: 0.0084 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 0.0023 - val_loss: 0.0077 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 0.0013 - val_loss: 0.0075 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 7.8910e-04 - val_loss: 0.0075 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 8.5528e-04 - val_loss: 0.0073 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 5.8592e-04 - val_loss: 0.0060 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 5.2394e-04 - val_loss: 0.0062 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 4.3525e-04 - val_loss: 0.0032 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 4.5582e-04 - val_loss: 0.0041 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 4.1867e-04 - val_loss: 0.0032 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 8s 167ms/step - loss: 7.0790e-04 - val_loss: 0.0043 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 8s 167ms/step - loss: 6.8441e-04 - val_loss: 0.0018 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 9s 170ms/step - loss: 8.3497e-04 - val_loss: 0.0044 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 9s 171ms/step - loss: 5.9207e-04 - val_loss: 4.6466e-04 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 9s 171ms/step - loss: 5.4806e-04 - val_loss: 0.0012 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 5.3001e-04 - val_loss: 0.0024 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 9s 171ms/step - loss: 6.1798e-04 - val_loss: 1.3727e-04 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 4.9516e-04 - val_loss: 7.5246e-04 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 3.8428e-04 - val_loss: 1.9425e-04 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 3.7316e-04 - val_loss: 2.6734e-04 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 4.1337e-04 - val_loss: 1.8939e-04 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 3.3275e-04 - val_loss: 5.2283e-04 - lr: 8.0000e-04\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 9s 171ms/step - loss: 1.6738e-04 - val_loss: 1.1887e-04 - lr: 8.0000e-04\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 9s 171ms/step - loss: 1.6846e-04 - val_loss: 1.2035e-05 - lr: 8.0000e-04\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 8s 170ms/step - loss: 1.9795e-04 - val_loss: 2.6271e-04 - lr: 8.0000e-04\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 8s 170ms/step - loss: 1.7821e-04 - val_loss: 3.7104e-04 - lr: 8.0000e-04\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.6810e-04 - val_loss: 8.0372e-06 - lr: 8.0000e-04\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 9s 171ms/step - loss: 1.7328e-04 - val_loss: 2.5986e-04 - lr: 8.0000e-04\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 1.0251e-04 - val_loss: 4.2120e-05 - lr: 6.4000e-04\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 7.2560e-05 - val_loss: 8.7728e-06 - lr: 6.4000e-04\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 7.0182e-05 - val_loss: 6.2158e-06 - lr: 6.4000e-04\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 5.6354e-05 - val_loss: 7.7934e-05 - lr: 6.4000e-04\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 9s 170ms/step - loss: 3.9155e-05 - val_loss: 2.3643e-05 - lr: 5.1200e-04\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 3.9031e-05 - val_loss: 1.8440e-05 - lr: 5.1200e-04\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 4.9102e-05 - val_loss: 2.0984e-05 - lr: 5.1200e-04\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 9s 170ms/step - loss: 4.3579e-05 - val_loss: 1.2798e-06 - lr: 5.1200e-04\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 8s 170ms/step - loss: 3.4683e-05 - val_loss: 1.6286e-05 - lr: 4.0960e-04\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 8s 170ms/step - loss: 3.2687e-05 - val_loss: 1.3651e-06 - lr: 4.0960e-04\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 3.1872e-05 - val_loss: 9.7537e-05 - lr: 4.0960e-04\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 8s 170ms/step - loss: 3.4542e-05 - val_loss: 8.8091e-05 - lr: 4.0960e-04\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 2.9981e-05 - val_loss: 9.4906e-05 - lr: 3.2768e-04\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 2.7004e-05 - val_loss: 7.2438e-05 - lr: 3.2768e-04\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 2.8079e-05 - val_loss: 6.8684e-05 - lr: 3.2768e-04\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 2.8732e-05 - val_loss: 1.3285e-04 - lr: 3.2768e-04\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 2.2861e-05 - val_loss: 7.9588e-05 - lr: 2.6214e-04\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 2.1657e-05 - val_loss: 6.1849e-05 - lr: 2.6214e-04\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 2.2707e-05 - val_loss: 1.8159e-05 - lr: 2.6214e-04\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 2.2405e-05 - val_loss: 3.8854e-05 - lr: 2.6214e-04\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 9s 171ms/step - loss: 1.9232e-05 - val_loss: 1.7068e-05 - lr: 2.0972e-04\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 8s 170ms/step - loss: 1.9732e-05 - val_loss: 2.2717e-06 - lr: 2.0972e-04\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.8554e-05 - val_loss: 1.9225e-05 - lr: 2.0972e-04\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.9207e-05 - val_loss: 7.3251e-05 - lr: 2.0972e-04\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 9s 171ms/step - loss: 1.6894e-05 - val_loss: 1.9615e-05 - lr: 1.6777e-04\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.6058e-05 - val_loss: 3.6248e-05 - lr: 1.6777e-04\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.6130e-05 - val_loss: 2.3917e-05 - lr: 1.6777e-04\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.5761e-05 - val_loss: 2.8331e-05 - lr: 1.6777e-04\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.6188e-05 - val_loss: 7.4251e-06 - lr: 1.3422e-04\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 1.3907e-05 - val_loss: 4.1062e-05 - lr: 1.3422e-04\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.4278e-05 - val_loss: 1.5337e-05 - lr: 1.3422e-04\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 9s 170ms/step - loss: 1.4650e-05 - val_loss: 1.5388e-05 - lr: 1.3422e-04\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.2940e-05 - val_loss: 3.0979e-05 - lr: 1.0737e-04\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.3046e-05 - val_loss: 1.5059e-05 - lr: 1.0737e-04\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 8s 170ms/step - loss: 1.2713e-05 - val_loss: 1.0868e-05 - lr: 1.0737e-04\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 1.3158e-05 - val_loss: 9.4331e-06 - lr: 1.0737e-04\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 9s 171ms/step - loss: 1.2942e-05 - val_loss: 1.1435e-06 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.1715e-05 - val_loss: 1.7610e-05 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.4106e-05 - val_loss: 2.4495e-06 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 9s 171ms/step - loss: 1.3194e-05 - val_loss: 2.4340e-05 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 8s 170ms/step - loss: 1.2855e-05 - val_loss: 3.6896e-05 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.2672e-05 - val_loss: 3.9900e-05 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.3079e-05 - val_loss: 9.5183e-06 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.2102e-05 - val_loss: 2.9686e-05 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.2957e-05 - val_loss: 1.2601e-05 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.3322e-05 - val_loss: 3.4177e-05 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.1506e-05 - val_loss: 1.0944e-05 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.3323e-05 - val_loss: 1.7764e-05 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.2756e-05 - val_loss: 3.6674e-05 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.3713e-05 - val_loss: 3.5640e-05 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 8s 170ms/step - loss: 1.4046e-05 - val_loss: 1.4414e-05 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 9s 170ms/step - loss: 1.2162e-05 - val_loss: 3.3203e-06 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 8s 170ms/step - loss: 1.3954e-05 - val_loss: 1.7060e-05 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 8s 170ms/step - loss: 1.3857e-05 - val_loss: 3.6625e-05 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.2420e-05 - val_loss: 2.5523e-06 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.2803e-05 - val_loss: 2.2229e-05 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 9s 170ms/step - loss: 1.5023e-05 - val_loss: 1.0066e-06 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.5806e-05 - val_loss: 9.6029e-06 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.4980e-05 - val_loss: 7.4012e-06 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.4808e-05 - val_loss: 1.5090e-06 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 1.4826e-05 - val_loss: 2.7575e-06 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 8s 167ms/step - loss: 1.6928e-05 - val_loss: 4.8896e-05 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 1.7728e-05 - val_loss: 5.6515e-05 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 1.7917e-05 - val_loss: 4.8115e-05 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 8s 167ms/step - loss: 1.6213e-05 - val_loss: 5.4776e-05 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 8s 167ms/step - loss: 1.6566e-05 - val_loss: 3.4309e-05 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 1.6748e-05 - val_loss: 5.9467e-05 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 8s 167ms/step - loss: 1.6221e-05 - val_loss: 1.3750e-05 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 1.5904e-05 - val_loss: 8.9636e-07 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 1.7616e-05 - val_loss: 1.3327e-06 - lr: 1.0000e-04\n",
            "CPU times: user 22min 37s, sys: 1min 23s, total: 24min 1s\n",
            "Wall time: 14min 24s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDwrXnRqlsOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist_df = pd.DataFrame(history.history) \n",
        "hist_csv_file = '/content/drive/My Drive/Capstone/FinalModels/Step2-DayTrade/Seed 10/'+model_file.split('.')[0]+'.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_OeIoQnlsOb",
        "colab_type": "code",
        "outputId": "fa6d95dd-5020-4965-c377-d13d1ee8e45b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['val_loss'][10:])\n",
        "plt.title('model_loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nShQ4RERkSv4fm+c7TBqraLgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjPIJsCGmOAt",
        "colab_type": "code",
        "outputId": "938f2d3e-1441-4240-c9ed-5e4a76a094bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['loss'][10:])\n",
        "plt.title('model_loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEWCAYAAABBvWFzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nimNS4IlXM9c",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WVjw3JgXSxy",
        "colab_type": "text"
      },
      "source": [
        "##Elaborate Predictions to compare with true values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzcemWUVlsOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The algorithm uses data of the previous 25 time-steps to forecast the following 10th minute into the future. Therefore,  \n",
        "# the first prediction of every day can only be excecuted after 25 minutes of the begining of the day, and will refer  \n",
        "# to the prediction of the minute 35. Also the data is first stationarized by apply the diff() function with then subtracts\n",
        "# the following row from the previous. \n",
        "\n",
        "# Since every day consists of 1440 minutes the algorithm is only able to predict the last 1404 minutes of the day.\n",
        "\n",
        "#Create a Dataframe to hold the true predicted values for each day.\n",
        "def createPredictionsData(days):  \n",
        "  predictionsData = DayTrade.copy()\n",
        "  predictionsData = predictionsData.loc[:,['Weighted_Price','date']]\n",
        "  predictionsData = predictionsData[predictionsData['date'].isin(days)]# Filter only the testing days\n",
        "  predictionsData = predictionsData.groupby('date').apply(lambda group: group.iloc[35:])# For each day filter the last 1405 minutes (1440 - 1405 = 35)\n",
        "  predictionsData = predictionsData.drop(columns='date')\n",
        "  predictionsData = predictionsData.reset_index()\n",
        "\n",
        "  return(predictionsData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNIHNgrDlsOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(modelFilename, days):\n",
        "\n",
        "    predictionsData = createPredictionsData(days)\n",
        "    \n",
        "    column_name = modelFilename.split('.')[0]\n",
        "    #Step 1 - Create a column to hold predictions\n",
        "    predictionsData['Prediction_Weighted_Price'] = np.nan #[3]\n",
        "    \n",
        "    \n",
        "    #Step 2 - load model for prediction   \n",
        "    loaded_model = tf.keras.models.load_model(modelFilename)\n",
        "    \n",
        "    for day in days:\n",
        "        #Step 3 - Filter Input data and Target with the selected date\n",
        "        day_test_data = DayTrade_clean[DayTrade_clean['date'].values==day]\n",
        "        day_label_data = target_data_clean[target_data_clean['date'].values==day]\n",
        "        \n",
        "        batch_size = len(day_test_data) - sequence_length\n",
        "         \n",
        "        \n",
        "        #Step 3 - Drop date columns from day test data and day label data\n",
        "        day_test_data = day_test_data.drop(columns=['date'])\n",
        "        day_label_data = day_label_data.drop(columns=['date']).shift(1)\n",
        "\n",
        "        #Step 4 - Convert day data into numpy array\n",
        "        day_test_data = np.array(day_test_data)\n",
        "        day_label_data = np.array(day_label_data)\n",
        "        \n",
        "        #Step 5 - Scale data for Neural Network (all features except Weighted Price)\n",
        "        day_test_data = x_scaler.transform(day_test_data)\n",
        "        day_label_data = y_scaler.transform(day_label_data)\n",
        "        \n",
        "               \n",
        "        #Step 6 - Generate batches of sequence of data\n",
        "        generator = TimeseriesGenerator(day_test_data, day_label_data, length=sequence_length, batch_size=batch_size)\n",
        "\n",
        "        x_batch = np.zeros(shape=(batch_size ,sequence_length, num_x_signal))\n",
        "        y_batch = np.zeros(shape=(batch_size ,sequence_length, num_y_signal))\n",
        "\n",
        "        x_batch, y_batch = generator[0]\n",
        "\n",
        "        #Step 9 - Generate the prediction for that day   \n",
        "        ypred = loaded_model.predict(x_batch)\n",
        "        ypred_rescaled = y_scaler.inverse_transform(ypred)\n",
        "        \n",
        "        index_list = []\n",
        "        index_list = predictionsData.index[predictionsData['date']==day].tolist()\n",
        "\n",
        "        predictionsData.iloc[index_list[0]:index_list[0]+len(index_list),3] = ypred_rescaled\n",
        "\n",
        "    \n",
        "    return(predictionsData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fU5aP2blsO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_file = 'DayTrade Model(seed 10).99-0.0000009.h5'\n",
        "modelPath = '/content/drive/My Drive/Capstone/FinalModels/Step2-DayTrade/Seed 10/'\n",
        "modelfilePath = modelPath + '/' + model_file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoCmeTw8lsPA",
        "colab_type": "code",
        "outputId": "78d8343d-a4b7-44bb-df5f-fbb7a625f881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "predictionsData = predict(modelfilePath, testing_days)\n",
        "predictionsData"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>Time</th>\n",
              "      <th>Weighted_Price</th>\n",
              "      <th>Prediction_Weighted_Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-02-19</td>\n",
              "      <td>2019-02-19 00:35:00</td>\n",
              "      <td>3901.527342</td>\n",
              "      <td>3953.322266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-02-19</td>\n",
              "      <td>2019-02-19 00:36:00</td>\n",
              "      <td>3910.106934</td>\n",
              "      <td>3954.385986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-02-19</td>\n",
              "      <td>2019-02-19 00:37:00</td>\n",
              "      <td>3913.037224</td>\n",
              "      <td>3953.604004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-02-19</td>\n",
              "      <td>2019-02-19 00:38:00</td>\n",
              "      <td>3933.854943</td>\n",
              "      <td>3950.048340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-02-19</td>\n",
              "      <td>2019-02-19 00:39:00</td>\n",
              "      <td>3935.166985</td>\n",
              "      <td>3950.693115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244465</th>\n",
              "      <td>2019-08-11</td>\n",
              "      <td>2019-08-11 23:55:00</td>\n",
              "      <td>11550.565971</td>\n",
              "      <td>11122.544922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244466</th>\n",
              "      <td>2019-08-11</td>\n",
              "      <td>2019-08-11 23:56:00</td>\n",
              "      <td>11552.336234</td>\n",
              "      <td>11112.181641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244467</th>\n",
              "      <td>2019-08-11</td>\n",
              "      <td>2019-08-11 23:57:00</td>\n",
              "      <td>11555.520505</td>\n",
              "      <td>11094.723633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244468</th>\n",
              "      <td>2019-08-11</td>\n",
              "      <td>2019-08-11 23:58:00</td>\n",
              "      <td>11559.252199</td>\n",
              "      <td>11075.010742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244469</th>\n",
              "      <td>2019-08-11</td>\n",
              "      <td>2019-08-11 23:59:00</td>\n",
              "      <td>11575.638889</td>\n",
              "      <td>11057.145508</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>244470 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              date  ... Prediction_Weighted_Price\n",
              "0       2019-02-19  ...               3953.322266\n",
              "1       2019-02-19  ...               3954.385986\n",
              "2       2019-02-19  ...               3953.604004\n",
              "3       2019-02-19  ...               3950.048340\n",
              "4       2019-02-19  ...               3950.693115\n",
              "...            ...  ...                       ...\n",
              "244465  2019-08-11  ...              11122.544922\n",
              "244466  2019-08-11  ...              11112.181641\n",
              "244467  2019-08-11  ...              11094.723633\n",
              "244468  2019-08-11  ...              11075.010742\n",
              "244469  2019-08-11  ...              11057.145508\n",
              "\n",
              "[244470 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s49G2-L4wTOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save Dataframe with prediction as csv file\n",
        "prediction_file = '/content/drive/My Drive/Capstone/FinalModels/Step2-DayTrade/Seed 10/'+'predictions_' +  model_file.split('.')[0] + '.csv'\n",
        "prediction_filePath = '/content/' + prediction_file\n",
        "predictionsData.to_csv(prediction_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud9T-Pf5Ia0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "mse_Weighted_Price = mean_squared_error(predictionsData.iloc[:,2],predictionsData.iloc[:,3])\n",
        "mae_Weighted_Price = mean_absolute_error(predictionsData.iloc[:,2],predictionsData.iloc[:,3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdWpW6ESIYUt",
        "colab_type": "code",
        "outputId": "aa7e57f3-7736-4d85-a67e-8ca5ca938f02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(mse_Weighted_Price,mae_Weighted_Price)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49279.00161704473 146.10810272405652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVFeor0CFUxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}